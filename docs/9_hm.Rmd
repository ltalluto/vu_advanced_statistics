---
title: "Hierarchical Models"
author: "Matthew Talluto"
date: "01.12.2020"
output:
  slidy_presentation:
    theme: cerulean
    toc_depth: 2
    css: rmd_style.css
---

```{r setup, include=FALSE, results = "hide"}
# knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width=8, fig.height=5.5, collapse = TRUE, comment = "##", dev="png")

library(ggplot2)
library(igraph)
library(ggnetwork)
library(data.table)
library(gridExtra)
library(rstan)
library(bayesplot)

cols = c("#F8766D", "#7CAE00", "#00BFC4", "#C77CFF")
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

```

## Temperature-mortality relationships in Tsuga

<div class="left lt">
* We return to the mortality of trees in North American forests
* The dataset contains information for multiple species and years
    - there is replication within units
* For now, we focus on *Tsuga canadensis*

</div>

<div class="right rt">
```{r}
trees = fread("exercises/data/treedata.csv")
tsuga = trees[grep("Tsuga", species_name)]
head(tsuga)
```

```{r echo=FALSE}
tab = table(trees[, .(species_name, year)])
tab = reshape2::melt(tab)
ggplot(tab, aes(x = species_name, y = as.factor(year), fill=value)) + 
	geom_tile() + scale_fill_viridis_c(option="magma") + theme_minimal() + xlab("Species") +
	ylab("Year") + labs(fill="sample size")
```

</div>



## Temperature-mortality relationships in Tsuga: H1

<div class="left lt">
* We return to the mortality of trees in North American forests
* The dataset contains information for multiple species and years
* For now, we focus on *Tsuga canadensis*
* **Hypothesis 1**: The temperature-mortality relationship is the same across all years (**Complete pooling**, 2 params)

</div>

<div class="right rt">
```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, p+-a, p+-b, p+-temperature, a+-"μ_a=0", a+-"σ_a=10", b+-"μ_b=0", b+-"σ_b=5")
V(gr)$type = c("random", "deterministic", "deterministic", "random", "random", rep("deterministic", 5))
V(gr)$source = c("known", "unknown", "known", "unknown", "unknown", rep("known", 5))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  -0.5,1,  0.5, 1,  0.5, 1.8, -0.75,0, -0.25,0,  0.25,0,  0.75,0), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_pool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05) + 
   annotate(geom="label", x = 1.3, y = -0.1, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.5, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5) + ggtitle("Complete Pooling")
grpl_pool
```

</div>




## Temperature-mortality relationships in Tsuga: H2

<div class="left lt">
* We return to the mortality of trees in North American forests
* The dataset contains information for multiple species and years
* For now, we focus on *Tsuga canadensis*
* **Hypothesis 1**: The temperature-mortality relationship is the same across all years (**Complete pooling**, 2 params)
* **Hypothesis 2**: The *average survival* varies by year, but the slope between temperature and mortality is constant (**Unpooled intercepts, pooled slopes**, 17 params)
    - Sample size by year ranges from 1 to 208
</div>


<div class="right rt">
```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, 
						p+-a1989, p+-"a1994...", p+-"...a2012",
						p+-b, p+-temperature, 
						a1989+-"μ_a=0", a1989+-"σ_a=10", 
						"a1994..."+-"μ_a=0", "a1994..."+-"σ_a=10",
						"...a2012"+-"μ_a=0", "...a2012"+-"σ_a=10",
						b+-"μ_b=0", b+-"σ_b=5")
V(gr)$type = c("random", "deterministic", "deterministic", 
			   rep("random", 4), rep("deterministic", 5))
V(gr)$source = c("known", "unknown", "known", rep("unknown", 4), rep("known", 5))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  
				  c(-0.5,1) + c(-0.1,0, 0,0, 0.1,0),  
				  0.5, 1,  0.5, 1.8, -0.75,0, -0.25,0,  0.25,0,  0.75,0), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_slpool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = -0.1, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.5, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5) + ggtitle("Pooled Slopes")
grpl_slpool
```
</div>



## Temperature-mortality relationships in Tsuga: H3

<div class="left lt">
* We return to the mortality of trees in North American forests
* The dataset contains information for multiple species and years
* For now, we focus on *Tsuga canadensis*
* **Hypothesis 1**: The temperature-mortality relationship is the same across all years (**Complete pooling**, 2 params)
* **Hypothesis 2**: The *average survival* varies by year, but the slope between temperature and mortality is constant (**Unpooled intercepts, pooled slopes**, 17 params)
    - Sample size by year ranges from 1 to 208
* **Hypothesis 3**: There is a different regression line for each year (**No pooling**, 32 parameters)

</div>

<div class="right rt">
```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, 
						p+-a1989, p+-"a1994...", p+-"...a2012",
						p+-b1989, p+-"b1994...", p+-"...b2012",
						p+-temperature, 
						a1989+-"μ_a=0", a1989+-"σ_a=10", 
						"a1994..."+-"μ_a=0", "a1994..."+-"σ_a=10",
						"...a2012"+-"μ_a=0", "...a2012"+-"σ_a=10",
						b1989+-"μ_b=0", b1989+-"σ_b=5", 
						"b1994..."+-"μ_b=0", "b1994..."+-"σ_b=5",
						"...b2012"+-"μ_b=0", "...b2012"+-"σ_b=5")
V(gr)$type = c("random", "deterministic", "deterministic", 
			   rep("random", 6), rep("deterministic", 5))
V(gr)$source = c("known", "unknown", "known", rep("unknown", 6), rep("known", 5))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  
				  c(-0.5,1) + c(-0.1,0, 0,0, 0.1,0), c(0.5,1) + c(-0.1,0, 0,0, 0.1,0),  
				  0.5, 1.8, -0.75,0, -0.25,0,  0.25,0,  0.75,0), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_nopool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = -0.1, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.5, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5) + ggtitle("No Pooling")
grpl_nopool
```
</div>


## Pooled models trade accuracy for precision

* All data for a single set of estimates
* High prediction errors for individual groups
* Groups with small samples biased towards the mean

```{stan output.var="tsuga_h1", cache = TRUE, echo = FALSE}
data {
	int <lower=0> n; // number of data points
	int <lower=1> n_trees [n]; // number of trees in each plot
	int <lower=0> died [n]; // number died

	vector [n] temperature;
}
parameters {
	real a;
	real b;
}
transformed parameters {
	vector <lower=0, upper=1> [n] p;
	p = inv_logit(a + b * temperature);
}
model {
	died ~ binomial(n_trees, p);
	a ~ normal(0, 10);
	b ~ normal(0, 5);
}
generated quantities {
	int died_sim [n];
	for (i in 1:n) {
		died_sim[i] = binomial_rng(n_trees[i], p[i]);
	}
}
```

```{r, cache = TRUE}
temperature = scale(tsuga$annual_mean_temp) ## note that I have rescaled temperature
standat = with(tsuga, list(
	n = length(died),
	n_trees = n,
	died = died,
	temperature = temperature[,1]))  
fit_h1 = sampling(tsuga_h1, chains=4, iter=3000, refresh=0, data = standat)
```

```{r, cache = TRUE, echo = FALSE, fig.width=18}
probs = as.matrix(fit_h1, pars='p')
quants = apply(probs, 2, quantile, c(0.5, 0.05, 0.95))
pldat = data.table(pr_obs = tsuga$died/tsuga$n, pred = quants[1,], lower = quants[2,], upper = quants[3,],
				   year = as.factor(tsuga$year))
prplot_h1 = ggplot(pldat, aes(x=pr_obs, y = pred, colour=year)) + geom_point() + geom_abline(intercept=0, slope=1, lty=2) + 
	geom_errorbar(aes(x=pr_obs, ymin=lower, ymax=upper, width=0)) + theme_minimal() + xlim(0,1) + ylim(0,1) + 
	xlab("Observed proportion surviving") + ylab("Predicted proportion surviving")

errs_by_sample = apply(probs, 1, function(x) (x - tsuga$died/tsuga$n)^2)
rmse_by_year = apply(errs_by_sample, 2, function(x) tapply(x, tsuga$year, function(y) sqrt(mean(y))))
rmse_by_year = data.table(t(apply(rmse_by_year, 1, quantile, c(0.5, 0.05, 0.95))))
colnames(rmse_by_year) = c("rmse", "lower", "upper")
rmse_by_year$year = levels(factor(tsuga$year))
rmse_by_year$n = as.vector(table(tsuga$year))
errpl_h1 = ggplot(rmse_by_year, aes(x = year, y = rmse, colour=n)) + geom_point() + 
	geom_errorbar(aes(x = year, ymin=lower, ymax=upper, width=0)) + 
	theme_minimal() + scale_colour_viridis_c(option="magma") + ylab("Mean Prediction Error")

intpl_h1 = mcmc_intervals(as.matrix(fit_h1, pars=c("a", "b"))) + theme_minimal()

grid.arrange(prplot_h1, errpl_h1, intpl_h1, ncol=3)
```





## Unpooled models use less data per parameter

<div class="right rt">

```{stan output.var="tsuga_h2", cache = TRUE, echo = TRUE}
data {
	int <lower=0> n; // number of data points
	
	// response
	int <lower=1> n_trees [n]; // number of trees in each plot
	int <lower=0> died [n]; // number died

	// predictors
	vector [n] temperature;
	
	// grouping
	int <lower=1> n_years;
	int <lower=1> year_id [n];
}
parameters {
	vector [n_years] a;
	real b;
}
transformed parameters {
	vector <lower=0, upper=1> [n] p;
	for(i in 1:n) {
		p[i] = inv_logit(a[year_id[i]] + b * temperature[i]);
	}
}
model {
	died ~ binomial(n_trees, p);
	a ~ normal(0, 10);
	b ~ normal(0, 5);
}

```
</div>



<div class="left lt">

* Very imprecise, especially for groups with few samples
* Prediction to new groups (years) impossible

```{r cache = TRUE, echo = TRUE, warning=FALSE}
## convert numerical year into an index, from 1:16
standat$year_id = as.integer(as.factor(tsuga$year))
standat$n_years = max(standat$year_id)
head(cbind(standat$year_id, tsuga$year))

fit_h2 = sampling(tsuga_h2, chains=4, iter=3000, refresh=0, data = standat)
```

</div>

## Unpooled models use less data per parameter

```{r, cache = TRUE, echo = FALSE, fig.width=18}
probs = as.matrix(fit_h2, pars='p')
quants = apply(probs, 2, quantile, c(0.5, 0.05, 0.95))
pldat = data.table(pr_obs = tsuga$died/tsuga$n, pred = quants[1,], lower = quants[2,], upper = quants[3,],
				   year = as.factor(tsuga$year))
prplot_h2 = ggplot(pldat, aes(x=pr_obs, y = pred, colour=year)) + geom_point() + geom_abline(intercept=0, slope=1, lty=2) + 
	geom_errorbar(aes(x=pr_obs, ymin=lower, ymax=upper, width=0)) + theme_minimal() + xlim(0,1) + ylim(0,1) + 
	xlab("Observed proportion surviving") + ylab("Predicted proportion surviving")

errs_by_sample = apply(probs, 1, function(x) (x - tsuga$died/tsuga$n)^2)
rmse_by_year = apply(errs_by_sample, 2, function(x) tapply(x, tsuga$year, function(y) sqrt(mean(y))))
rmse_by_year = data.table(t(apply(rmse_by_year, 1, quantile, c(0.5, 0.05, 0.95))))
colnames(rmse_by_year) = c("rmse", "lower", "upper")
rmse_by_year$year = levels(factor(tsuga$year))
rmse_by_year$n = as.vector(table(tsuga$year))
errpl_h2 = ggplot(rmse_by_year, aes(x = year, y = rmse, colour=n)) + geom_point() + 
	geom_errorbar(aes(x = year, ymin=lower, ymax=upper, width=0)) + 
	theme_minimal() + scale_colour_viridis_c(option="magma") + ylab("Mean Prediction Error")

intpl_h2 = mcmc_intervals(as.matrix(fit_h2, pars=c("a", "b"))) + theme_minimal()

grid.arrange(prplot_h2, errpl_h2, intpl_h2, ncol=3)
```







## Partial Pooling
<div class="right rt">
```{stan output.var="tsuga_h2pp", cache = TRUE, echo = TRUE}
data {
	int <lower=0> n; // number of data points
	
	// response
	int <lower=1> n_trees [n]; // number of trees in each plot
	int <lower=0> died [n]; // number died

	// predictors
	vector [n] temperature;
	
	// grouping
	int <lower=1> n_years;
	int <lower=1> year_id [n];
}
parameters {
	vector [n_years] a;
	real b;
	
	real a_mu; // average intercept by year
	real <lower=0> a_sig; // sd of intercepts
}
transformed parameters {
	vector [n] p;
	for(i in 1:n) {
		p[i] = inv_logit(a[year_id[i]] + b * temperature[i]);
	}
}
model {
	died ~ binomial(n_trees, p);
	// priors
	a ~ normal(a_mu, a_sig); // hierarchical prior for a
	b ~ normal(0, 5);

	a_mu ~ normal(0, 10);
	a_sig ~ gamma(0.1, 0.1);
}
generated quantities {
	int died_sim [n];
	for (i in 1:n) {
		died_sim[i] = binomial_rng(n_trees[i], p[i]);
	}
}
```
</div>


<div class="left lt">
* We don't really expect each year to be independent
    - it's all one species, response to temperature should be similar
    - some years are better or worse than others
* Imagine instead there is a population of possible years, each with its own mortality
* This population has a true mean and a true variance
* The samples we've taken will come from that distribution
* This can tell us something about all possible years, not just these years


```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, 
						p+-a1989, p+-"a1994...", p+-"...a2012",
						p+-b, p+-temperature, 
						a1989+-"μ_a", a1989+-"σ_a", 
						"a1994..."+-"μ_a", "a1994..."+-"σ_a",
						"...a2012"+-"μ_a", "...a2012"+-"σ_a",
						b+-"μ_b=0", b+-"σ_b=5", 
						"μ_a"+-"N(0,10)", "σ_a"+-"G(0.1,0.1)")
V(gr)$type = c("random", "deterministic", "deterministic", 
			   rep("random", 4), "deterministic", rep("random", 2), rep("deterministic", 4))
V(gr)$source = c("known", "unknown", "known", rep("unknown", 4), "known", rep("unknown", 2), rep("known", 4))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  
				  c(-0.5,1) + c(-0.1,0, 0,0, 0.1,0), 0.5,1,  
				  0.5, 1.8, -0.75,0, -0.25,0,  0.25,0,  0.75,0,  -0.75,-1, -0.25,-1), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_ppool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = 0, label = "Hyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.3, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.67, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5) + ggtitle("Partial Pooling")
grpl_ppool
```


</div>





## Partial pooling is a compromise

* for a given group, we combine the information for this group with information from all groups
* balances precision and accuracy
* can be best approach for new groups
* weak/undersampled groups can "borrow strength" from others


```{r cache = TRUE, warning=FALSE}
fit_h2pp = sampling(tsuga_h2pp, chains=4, iter=3000, refresh=0, data = standat)
```





```{r, cache = TRUE, echo = FALSE, fig.width=18}
probs = as.matrix(fit_h2pp, pars='p')
quants = apply(probs, 2, quantile, c(0.5, 0.05, 0.95))
pldat = data.table(pr_obs = tsuga$died/tsuga$n, pred = quants[1,], lower = quants[2,], upper = quants[3,],
				   year = as.factor(tsuga$year))
prplot_h2pp = ggplot(pldat, aes(x=pr_obs, y = pred, colour=year)) + geom_point() + geom_abline(intercept=0, slope=1, lty=2) + 
	geom_errorbar(aes(x=pr_obs, ymin=lower, ymax=upper, width=0)) + theme_minimal() + xlim(0,1) + ylim(0,1) + 
	xlab("Observed proportion surviving") + ylab("Predicted proportion surviving")

errs_by_sample = apply(probs, 1, function(x) (x - tsuga$died/tsuga$n)^2)
rmse_by_year = apply(errs_by_sample, 2, function(x) tapply(x, tsuga$year, function(y) sqrt(mean(y))))
rmse_by_year = data.table(t(apply(rmse_by_year, 1, quantile, c(0.5, 0.05, 0.95))))
colnames(rmse_by_year) = c("rmse", "lower", "upper")
rmse_by_year$year = levels(factor(tsuga$year))
rmse_by_year$n = as.vector(table(tsuga$year))
errpl_h2pp = ggplot(rmse_by_year, aes(x = year, y = rmse, colour=n)) + geom_point() + 
	geom_errorbar(aes(x = year, ymin=lower, ymax=upper, width=0)) + 
	theme_minimal() + scale_colour_viridis_c(option="magma") + ylab("Mean Prediction Error")

intpl_h2pp = mcmc_intervals(as.matrix(fit_h2pp, pars=c("a", "b"))) + theme_minimal()

grid.arrange(prplot_h2pp, errpl_h2pp, intpl_h2pp, ncol=3)
```




## Pooling comparison
```{r echo = FALSE, fig.width=18}
grid.arrange(errpl_h1 + ggtitle("Pooled") + ylim(0, 0.9), 
			 errpl_h2 + ggtitle("Unpooled") + ylim(0, 0.9), 
			 errpl_h2pp + ggtitle("Partially Pooled") + ylim(0, 0.9), ncol=3)
```

## Pooling comparison
```{r echo = FALSE, fig.width=18}
grid.arrange(intpl_h1 + ggtitle("Pooled"), 
			 intpl_h2 + ggtitle("Unpooled"), 
			 intpl_h2pp + ggtitle("Partially Pooled"), ncol=3)
```


## When do we need hierarchical models?
* Repeated sampling within units (e.g., samples nested within plots/individuals)
* Inference at multiple levels of organisation
    - Covariates at multiple spatial scales
* Uneven sampling among units
* Accounting for nonindependence of samples
* Avoiding pre-averaging
    - Don't: perform repeat samples on a unit, perform analysis on the average
    - Do: Build an HM accounting for variability within and among units
* A common category of HM is often called mixed modeling
    - All mixed models are hierarchical, not all hierarchical models are mixed models



## Designing hierarchical models in Stan
<div class="left lt">
* You must specify data/objects at all levels
* Often we use an indexing variable to link observations to their group
* This variable **must** start at 1 and end at *n_groups*

</div>

<div class="right rt">
```{stan output.var="stan_hm", eval = FALSE}
data {
	// group-level objects
	int <lower=1> n_groups;
	int <lower=1, upper=n_groups> group_id [n];
}
parameters {
	vector [n_groups] a; 
	
	// hyperparameters
	real a_mu;
	real a_sig;
}
transformed parameters {
	pr[i] = inv_logit(a[group_id[i]]);
}
model {
	a ~ normal(a_mu, a_sig);  // hierarchical prior for a
}
```
</div>


## Designing hierarchical models in Stan
<div class="left lt">
* You must specify data/objects at all levels
* Often we use an indexing variable to link observations to their group
* This variable **must** start at 1 and end at *n_groups*
* Multiple non-nested groups are possible



```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, p+-temperature,
						p+-a1_n, p+-a2_n, p+-b,
						a1_n+-"μ_a1", a1_n+-"σ_a1", 
						a2_n+-"μ_a2", a2_n+-"σ_a2",
						b+-"μ_b=0", b+-"σ_b=5", 
						"μ_a1"+-"N(0,10)", "σ_a1"+-"G(0.1,0.1)",
						"μ_a2"+-"N(0,10)", "σ_a2"+-"G(0.1,0.1)")
V(gr)$type = c("random", rep("deterministic", 3), rep("random", 7), rep("deterministic", 4))
V(gr)$source = c("known", "unknown", rep("known", 2), rep("unknown", 7), rep("known", 4))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  0.5,1.8,
				  -0.5,1,  -1,1,  0.5,1,  
				   -0.7,0, -0.3,0,  -1.2,0, -0.8,0,  0.25,0,  0.75,0,  -0.8,-1, -0.3,-1), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_hm1 = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = 0, label = "Hyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.3, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.67, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5)
grpl_hm1
```





</div>

<div class="right rt">
```{stan output.var="stan_hm", eval = FALSE}
data {
	int n; // number of data points
	int died [n]
	int N[n];
	vector [n] temperature;

	// group-level objects
	int <lower=1> n_group1;
	int <lower=1, upper=n_group1> group1_id [n];

	int <lower=1> n_group2;
	int <lower=1, upper=n_group2> group2_id [n];
}
parameters {
	vector [n_group1] a1; 
	vector [n_group2] a2; 
	
	// hyperparameters
	real a1_mu;
	real <lower=0> a1_sig;
	real a2_mu;
	real <lower=0> a2_sig;
}
transformed parameters {
	vector [n] pr;
	for(i in 1:n)
		pr[i] = inv_logit(a1[group1_id[i]] + a2[group2_id[i]] + b*temperature[i]);
}
model {
	died ~ binomial(N, pr); // likelihood

	a1 ~ normal(a1_mu, a1_sig);  // hierarchical prior for a1
	a2 ~ normal(a2_mu, a2_sig);  // hierarchical prior for a2

	// hyperpriors
	a1_mu ~ normal(0,10)
	a2_mu ~ normal(0,10)
	a1_sig ~ gamma(0.1, 0.1);
	a2_sig ~ gamma(0.1, 0.1);
}
```

</div>





## Designing hierarchical models in Stan
<div class="left lt">
* You must specify data/objects at all levels
* Often we use an indexing variable to link observations to their group
* This variable **must** start at 1 and end at *n_groups*
* Multiple non-nested groups are possible
* Nested groups add an additional hierarchical layer


```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, p+-temperature,
						p+-a1_n, a1_n+-a2_n, p+-b,
						a1_n+-"σ_a1", 
						a2_n+-"μ_a2", a2_n+-"σ_a2",
						b+-"μ_b=0", b+-"σ_b=5", 
						"σ_a1"+-"G(0.1,0.1)",
						"μ_a2"+-"N(0,10)", "σ_a2"+-"G(0.1,0.1)")
V(gr)$type = c("random", rep("deterministic", 3), rep("random", 6), rep("deterministic", 4))
V(gr)$source = c("known", "unknown", rep("known", 2), rep("unknown", 6), rep("known", 4))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  0.5,1.8,
				  -0.5,1,  -0.75,0,  0.5,1,  
				   -0.3,0,  -1,-1, -0.5,-1, 0.25,0,  0.75,0,  -0.1,-1.2, -1,-2), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_hm2 = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = 0, label = "Hyperhyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.25, label = "Hyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.5, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.75, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5)
grpl_hm2
```


</div>

<div class="right rt">
```{stan output.var="stan_hm", eval = FALSE}
data {
	int n; // number of data points
	int died [n]
	int N[n];
	vector [n] temperature;

	// group-level objects
	int <lower=1> n_group1;
	int <lower=1, upper=n_group1> group1_id [n];

	int <lower=1> n_group2;
	int <lower=1, upper=n_group2> group2_id [n_group1];
}
parameters {
	vector [n_group1] a1; 
	vector [n_group2] a2; 
	
	// hyperparameters
	real <lower=0> a1_sig;
	real a2_mu;
	real <lower=0> a2_sig;
}
transformed parameters {
	vector [n] pr;
	for(i in 1:n)
		pr[i] = inv_logit(a1[group1_id[i]] + b*temperature[i]);
}
model {
	died ~ binomial(N, pr); // likelihood

	for(i in n_group1)
		a1 ~ normal(a2[i], a1_sig);  // hierarchical prior for a1
	// hyperpriors
	a2 ~ normal(a2_mu, a2_sig);  // hierarchical prior for a2
	a1_sig ~ gamma(0.1, 0.1);
	
	// hyperhyperprior
	a2_mu ~ normal(0,10)
}
```
</div>




## Posterior predictive distributions
* Note also that posterior prediction gets harder
* Do we want to predict new observations from a known group? 
    - Same as before, can be easily done in Stan
* Or new observations from an unknown group?
    - Do in R
    - For each sim, draw values for the hyperparams (group-level effects)
    - Then simulate the individual observations

```{r cache=TRUE}
sim1 = function(N, temperature, amu, asig, b) {
	a = rnorm(length(temperature), amu, asig)
	p = plogis(a + b*temperature)
	rbinom(length(temperature), N, p)
}
newx = seq(min(standat$temperature), max(standat$temperature), length.out=400)
pars = as.matrix(fit_h2pp, pars=c("a_mu", "a_sig", "b"))

# For our hypothetical, we need to decide how many trees we would see
# more trees means less sampling uncertainty
N = 20
sims = apply(pars, 1, function(x) 
	sim1(N=N, temperature = newx, amu=x['a_mu'], asig = x['a_sig'], b = x['b']))
sim_qs = t(apply(sims, 1, quantile, c(0.5, 0.05, 0.95)))

## undo the scaling so we can see the plot on the original scale
newx_unscale = (newx * sd(tsuga$annual_mean_temp)) + mean(tsuga$annual_mean_temp)
plot(newx_unscale, sim_qs[,1]/N, type='l', bty='n', ylim = c(0,1),
	 xlab = "Annual Mean Temperature", ylab = "Predicted mortality", col=cols[1])
polygon(c(newx_unscale, rev(newx_unscale)), c(sim_qs[,2], rev(sim_qs[,3]))/N, 
		border=NA, col=paste0(cols[1], '55'))
```

