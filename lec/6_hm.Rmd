---
title: "Hierarchical Models"
author: "M. Talluto"
date: "01.12.2023"
output:
  slidy_presentation:
    theme: cerulean
    toc_depth: 2
    css: rmd_style.css
    self_contained: false
    lib_dir: lib
  beamer_presentation: default
---

```{r setup, include=FALSE, results = "hide"}
# knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width=8, fig.height=5.5, collapse = TRUE, comment = "##", dev="png", error=TRUE)

library(ggplot2)
library(sf)
library(rstan)
library(bayesplot)


library(igraph)
library(ggnetwork)
library(data.table)
library(gridExtra)

cols = c("#F8766D", "#7CAE00", "#00BFC4", "#C77CFF")
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

```

## Kidney cancer death rates in the US
::: {.columns}
:::: {.column}

* Kidney cancer death rates in the US, by county
* Is there a geographic pattern? If so, why?

:::: {.small}
Data source: Gelman et al. 2004. [Bayesian Data Analysis](http://www.stat.columbia.edu/~gelman/book/).
::::

::::
:::: {.column}

```{r cancer_map, cache = TRUE, echo = FALSE, message = FALSE}
invisible(capture.output(counties <- st_read("../vu_advstats_students/data/us_k_cancer_spatial.gpkg")))

pl_cancer = ggplot(counties) + 
	geom_sf(aes(fill = death_rate_per_1000, colour = death_rate_per_1000)) + 
	scale_fill_viridis_c("Death rate", option = "rocket") + 
	scale_colour_viridis_c("Death rate", option = "rocket")
pl_cancer
```

::::
:::

## Kidney cancer death rates in the US
::: {.columns}
:::: {.column}

* Kidney cancer death rates in the US, by county
* Is there a geographic pattern? If so, why?

::::
:::: {.column}

```{r cancer_quantile_map, cache = TRUE, echo = FALSE, message = FALSE}

cols = c("#e31a1c", "#1f78b4", "#ffffff")
pl_c_quantile = ggplot(counties) + 
	geom_sf(aes(fill = factor(quantile)), colour = "#555555", linewidth = 0.2) + 
	scale_discrete_manual("Quantile", aesthetics = "fill", values = cols)

pl_c_quantile
```

::::
:::

## Kidney cancer death rates in the US
::: {.columns}
:::: {.column}

* Kidney cancer death rates in the US, by county
* Is there a geographic pattern? If so, why?

![](https://imgs.xkcd.com/comics/heatmap_2x.png){width=400px}

::::
:::: {.column}

```{r cancer_quantile_map2, cache = TRUE, echo = FALSE, message = FALSE}
pl_c_quantile
```

::::
:::




## Kidney cancer death rates in the US
::: {.columns}
:::: {.column}

* Kidney cancer death rates in the US, by county
* Is there a geographic pattern? If so, why?
* How can we estimate county-specific rates in a reasonable way?

```{r pop_map, cache = TRUE, echo = FALSE, message = FALSE, warning=FALSE}

ggplot(counties) + 
	geom_sf(aes(fill = population, colour = population)) + 
	scale_fill_viridis_c("Population size", option = "magma", trans = "log10") + 
	scale_colour_viridis_c("Population size", option = "magma", trans = "log10")

```

::::
:::: {.column}

```{r cancer_quantile_combo, cache = TRUE, echo = FALSE, message = FALSE, fig.height = 8}
grid.arrange(pl_cancer, pl_c_quantile, ncol = 1)
```

::::
:::


## Kidney cancer Stan model: global/constant rate
::: {.columns}
:::: {.column}

* Our data are counts, suggesting Poisson
	- We don't use binomial in part because we care about death **rate**, not probability
* Here we build a model accounting for **exposure** (population size)
* We assume mortality rate $\lambda$ is constant for the entire dataset
	- $\lambda$ is **pooled** across units (county)


::::
:::: {.column}

```{r cancer_data, message = FALSE}
library(data.table)
(cancer = readRDS("../vu_advstats_students/data/us_k_cancer.rds"))
```

::::
:::




## Kidney cancer Stan model: global/constant rate
::: {.columns}
:::: {.column}

* Our data are counts, suggesting Poisson
	- We don't use binomial in part because we care about death **rate**, not probability
* Here we build a model accounting for **exposure** (population size)
* We assume mortality rate $\lambda$ is constant for the entire dataset
	- $\lambda$ is **pooled** across units (county)


::::
:::: {.column}


```{stan stan_cancer_pooled, cache = TRUE, output.var = "cancer_pooled"}
data {
	int <lower = 1> n;
	int <lower = 0> deaths [n];
	int <lower = 0> population [n];
	real <lower = 0> alpha;
	real <lower = 0> beta;
}
transformed data {
	// cancer is rare, lets make the numbers more reasonable
	vector <lower = 0> [n] exposure;
	for(i in 1:n)
		exposure[i] = population[i] / 1000.0;
}
parameters {
	real <lower = 0> lambda;
}
model {
	deaths ~ poisson(exposure * lambda);
	lambda ~ gamma(alpha, beta);
}
```

::::
:::




## Kidney cancer Stan model: global/constant rate
::: {.columns}
:::: {.column}

* Our data are counts, suggesting Poisson
	- We don't use binomial in part because we care about death **rate**, not probability
* Here we build a model accounting for **exposure** (population size)
* We assume mortality rate $\lambda$ is constant for the entire dataset
	- $\lambda$ is **pooled** across units (county)
	- Interpretation of $\lambda$: cancer deaths per five years per 1000 people
	
**Question**: Is there geographic variation in cancer rates?


::::
:::: {.column}

```{r cancer_pooled_compile, eval = FALSE}
library(rstan)
cancer_pooled = stan_model("stan/kidney_cancer_pooled.stan")
```

```{r fit_cancer_pooled, cache = TRUE}
cancer = cancer[complete.cases(cancer)]
cancer_data_stan = list(
	n = nrow(cancer),
	deaths = cancer$kidney_cancer_deaths,
	population = cancer$population,
	alpha = 0.01, # extremely vague priors, probably too vague!
	beta = 0.01
)
cancer_p_fit = sampling(cancer_pooled, data = cancer_data_stan, refresh = 0)
quantile(as.matrix(cancer_p_fit, pars = "lambda")[,1], c(0.05, 0.95))
```

::::
:::






## Kidney cancer Stan model: rates per county

::: {.columns}
:::: {.column}

* We assume mortality rate $\lambda$ is independent for each county
	- $\lambda$ is **unpooled** across units (county)
* This model has a lot of parameters, and doesn't fit well
* Max of 2 observations per lambda!


::::
:::: {.column}


```{stan stan_cancer_unpooled, output.var = "cancer_unpooled", eval = FALSE}
data {
	int <lower = 1> n;
	int <lower = 1> n_counties;
	int <lower = 0> deaths [n];
	int <lower = 0> population [n];
	int <lower = 0, upper = n_counties> county_id [n];
	real <lower = 0> alpha;
	real <lower = 0> beta;
}
transformed data {
	// cancer is rare, lets make the numbers more reasonable
	vector <lower = 0> [n] exposure;
	for(i in 1:n)
		exposure[i] = population[i] / 1000.0;
}
parameters {
	vector <lower = 0> [n_counties] lambda;
}
model {
	for(i in 1:n) {
		int j = county_id[i];
		deaths[i] ~ poisson(exposure[i] * lambda[j]);
	}
	lambda ~ gamma(alpha, beta);
}
```

::::
:::



## Kidney cancer Stan model: partial pooling

::: {.columns}
:::: {.column}

* We can use the overall rate for the whole country as a prior for individual counties
* Areas with few observations will use the whole country as a slight reality check
* $\lambda$ is **partially pooled**

```{r, echo = FALSE, fig.width=8, warning = FALSE}
gr = graph_from_literal(deaths+-lambda, lambda+-alpha, lambda+-beta, deaths+-exposure, alpha+-aa, alpha+-ba, 
						beta+-ab, beta+-bb)
V(gr)$type = c(rep("random", 4), rep("deterministic", 5))
V(gr)$source = c("known", rep("unknown", 3), rep("known", 5))

layout = rbind(deaths = c(0, 3), lambda = c(0, 2), alpha = c(-0.5, 1), beta = c(0.5, 1), 
			   exposure = c(0.5, 3), alpha_a = c(-0.75, 0), beta_a = c(-0.25, 0), 
			   alpha_b = c(0.25, 0), beta_b = c(0.75, 0))

n = ggnetwork(gr, layout=layout)
nlabs = c(expression(alpha[alpha]), expression(alpha), expression(beta[alpha]), expression(lambda), 
		  expression(alpha[beta]), expression(beta), "exposure", expression(beta[beta]), "deaths")

grpl_pool = ggplot(n, aes(x = x, y = y, xend = xend, yend = yend)) + 
	geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), 
			type = "closed")) + 
	theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
	# geom_nodelabel(aes(label = name), fontface = "bold", nudge_x=-0.1) +
	geom_nodelabel(label = nlabs, fontface = "bold", nudge_x=-0.1) +
	annotate(geom = "label", x = 1.3, y = 1, label = "Data") +
	annotate(geom = "label", x = 1.3, y = 0.67, label = "Parameters") +
	annotate(geom = "label", x = 1.3, y = 0.33, label = "Priors/Hyperparameters") +
	annotate(geom = "label", x = 1.3, y = 0, label = "Hyper-Hyperparameters") +
	# geom_label(aes(x=1.3, y=1), label = "Data") +
	# geom_label(aes(x=1.3, y=0.5), label = "Parameters") +
	# geom_label(aes(x=1.3, y=0), label = "Priors/Hyperparameters") +
	# geom_label(aes(x=1.3, y=-0.5), label = "Hyper-Hyperparameters") +
	xlim(-0.1, 1.6)
grpl_pool


```

::::
:::: {.column}


```{stan stan_cancer_ppooled, cache = TRUE, output.var = "cancer_ppooled"}
data {
	int <lower = 1> n;
	int <lower = 1> n_counties;
	int <lower = 0> deaths [n];
	int <lower = 0> population [n];
	int <lower = 0, upper = n_counties> county_id [n];

	// hyper-hyper parameters, for the hyperprior
	real <lower = 0> a_alpha;
	real <lower = 0> a_beta;
	real <lower = 0> b_alpha;
	real <lower = 0> b_beta;
}
transformed data {
	// cancer is rare, lets make the numbers more reasonable
	vector <lower = 0> [n] exposure;
	for(i in 1:n)
		exposure[i] = population[i] / 1000.0;
}
parameters {
	vector <lower = 0> [n_counties] lambda;
	
	// prior hyperparameters for lambda are now parameters we will estimate!
	real <lower = 0> alpha;
	real <lower = 0> beta;
	
}
model {
	for(i in 1:n) {
		int j = county_id[i];
		deaths[i] ~ poisson(exposure[i] * lambda[j]);
	}
	
	// prior for lambda
	lambda ~ gamma(alpha, beta);
	
	// hyperpriors for alpha and beta
	alpha ~ gamma(a_alpha, a_beta);
	beta ~ gamma(b_alpha, b_beta);
}
generated quantities {
	// save the overal mean and variance in cancer rate
	real lambda_mu = alpha/beta;
	real lambda_var = alpha/beta^2;
}
```

::::
:::





## Kidney cancer Stan model: partial pooling
::: {.columns}
:::: {.column}

* We can use the overall rate for the whole country as a prior for individual counties
* Areas with few observations will use the whole country as a slight reality check
* $\lambda$ is **partially pooled**
* Parameters with limited information can **borrow strength** from the rest of the dataset
* We must take care when choosing the hyperprior parameters
	- this cancer is rare, less than one per 1000 on average
	- we choose a range for alpha and beta that is wide, but makes mostly impossible values very unlikely

::::
:::: {.column}

```{r cancer_ppooled_priors, cache = TRUE}
mean(cancer$death_rate_per_1000/(cancer$population/1000))
sd(cancer$death_rate_per_1000/(cancer$population/1000))
alpha_a = 0.01
beta_a = 1

# our hyperparameter alpha has a 99% prob of being between these two values
(a_int = qgamma(c(0.01, 0.99), alpha_a, beta_a))

alpha_b = 0.8
beta_b = 0.4
# our hyperparameter alpha has a 99% prob of being between these two values
(b_int = (round(qgamma(c(0.01, 0.99), alpha_b, beta_b), 2)))

## what would the mean lambda look like at these extremes?
round(matrix(c(a_int[1] / b_int[1], a_int[2]/b_int[1], a_int[1] / b_int[2], a_int[2] / b_int[2]), nrow = 2, 
	   dimnames = list(c("min a", "max a"), c("min b", "max b"))),2)

cancer_data_stan$a_alpha = alpha_a
cancer_data_stan$b_alpha = alpha_b
cancer_data_stan$a_beta = beta_a
cancer_data_stan$b_beta = beta_b
```

::::
:::




## Kidney cancer Stan model: partially pooled rates per county
::: {.columns}
:::: {.column}

* We can use the overall rate for the whole country as a prior for individual counties
* Areas with few observations will use the whole country as a slight reality check
* $\lambda$ is **partially pooled**
* Parameters with limited information can **borrow strength** from the rest of the dataset
* We must take care when choosing the hyperprior parameters
	- this cancer is rare, less than one per 1000 on average
	- we choose a range for alpha and beta that is wide, but makes mostly impossible values very unlikely

::::
:::: {.column}


```{r cancer_ppooled_compile, eval = FALSE}
library(rstan)
cancer_unpooled = stan_model("stan/kidney_cancer_ppooled.stan")
```

```{r fit_cancer_ppooled, cache = TRUE}
cancer$county_id = as.integer(factor(cancer$county))
cancer_data_stan$county_id = cancer$county_id
cancer_data_stan$n_counties = max(cancer$county_id)

cancer_ppool_fit = sampling(cancer_ppooled, data = cancer_data_stan, refresh = 0, iter = 5000)
cancer_ppool_samps = as.matrix(cancer_ppool_fit, pars = "lambda")
quants = t(apply(cancer_ppool_samps , 2, quantile, c(0.05, 0.95)))
head(quants)

# quantile interval for the overall mean
round(rbind(pooled = quantile(as.matrix(cancer_p_fit, pars = "lambda"), c(0.05, 0.95)),
	partial_pooled = quantile(as.matrix(cancer_ppool_fit, pars = "lambda_mu"), c(0.05, 0.95))), 4)
```



::::
:::




## Kidney cancer Stan model: partially pooled maps

``` {r cancer_fit_maps, echo = FALSE, cache = TRUE, fig.width = 12}
lam_med = apply(cancer_ppool_samps, 2, median)
lam_sd = apply(cancer_ppool_samps, 2, sd)
cancer_flat = unique(cancer[,.(state, county, county_id)])

cancer_flat$cancer_rate_fit = lam_med[cancer_flat$county_id]
cancer_flat$cancer_rate_se = lam_sd[cancer_flat$county_id]

counties = merge(counties, cancer_flat, by = c("state", "county"), all.x = TRUE)
pl_c_death_fit = ggplot(counties) + geom_sf(aes(fill = cancer_rate_fit, colour = cancer_rate_fit)) + 
	scale_fill_viridis_c("Death rate", option = "rocket") + 
	scale_colour_viridis_c("Death rate", option = "rocket") + 
	ggtitle("Kidney Cancer Rate (Hierarchical Model)")

pl_c_death_sd = ggplot(counties) + geom_sf(aes(fill = cancer_rate_se, colour = cancer_rate_se)) + 
	scale_fill_viridis_c("Death rate", option = "inferno") + 
	scale_colour_viridis_c("Death rate", option = "inferno") + 
	ggtitle("Kidney Cancer Rate Standard Error (Hierarchical Model)")

counties$new_quantile = with(counties, cut(cancer_rate_fit, 
				breaks = quantile(cancer_rate_fit, c(0, 0.1, 0.9, 1), na.rm = TRUE), 
				labels = c("Lowest 10%", "Middle", "Highest 10%")))
pl_c_quantile_fit = ggplot(counties) + 
	geom_sf(aes(fill = factor(new_quantile)), colour = "#555555", linewidth = 0.2) + 
	scale_discrete_manual("Quantile", aesthetics = "fill", values = cols[c(2, 3, 1)]) + 
	ggtitle("Kidney Cancer Quantiles (Hierarchical Model)")

grid.arrange(pl_c_death_fit, pl_c_death_sd, nrow = 1)
```

## Kidney cancer Stan model: partially pooled maps

``` {r cancer_fit_maps2, echo = FALSE, cache = TRUE, fig.width = 12}
grid.arrange(pl_c_quantile_fit, pl_c_quantile + ggtitle("Kidney Cancer Quantiles (Raw)"), nrow = 1)


```














## Precipitation-mortality relationships in Tsuga

::: {.columns}
:::: {.column}
* We return to the mortality of trees in North American forests
* The dataset contains information for multiple species and years
    - there is replication within units
* For now, we focus on *Tsuga canadensis*

::::
:::: {.column}
```{r}
trees = fread("../vu_advstats_students/data/treedata.csv")
tsuga = trees[grep("Tsuga", species_name)]
# remove NAs
tsuga = tsuga[complete.cases(tsuga), ]
head(tsuga)
```

```{r echo=FALSE}
tab = table(trees[, .(species_name, year)])
tab = reshape2::melt(tab)
ggplot(tab, aes(x = species_name, y = as.factor(year), fill=value)) + 
	geom_tile() + scale_fill_viridis_c(option="magma") + theme_minimal() + xlab("Species") +
	ylab("Year") + labs(fill="sample size")
```

::::
:::



## Precipitation-mortality relationships in Tsuga: H1

::: {.columns}
:::: {.column}
* **Question:** Does mortality of *Tsuga canadensis* vary with precipitation?
	- The species generally prefers moist conditions
* **Hypothesis 1**: The precipitation-mortality relationship is the same across all years (**Complete pooling**, 2 params)

::::
:::: {.column}
```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, p+-a, p+-b, p+-precip, a+-"μ_a=0", a+-"σ_a=10", b+-"μ_b=0", b+-"σ_b=5")
V(gr)$type = c("random", "deterministic", "deterministic", "random", "random", rep("deterministic", 5))
V(gr)$source = c("known", "unknown", "known", "unknown", "unknown", rep("known", 5))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  -0.5,1,  0.5, 1,  0.5, 1.8, -0.75,0, -0.25,0,  0.25,0,  0.75,0), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_pool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05) + 
   annotate(geom="label", x = 1.3, y = -0.1, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.5, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5) + ggtitle("Complete Pooling")
grpl_pool
```

::::
:::




## Precipitation-mortality relationships in Tsuga: H2

::: {.columns}
:::: {.column}
* **Question:** Does mortality of *Tsuga canadensis* vary with precipitation?
	- The species generally prefers moist conditions
* **Hypothesis 1**: The precipitation-mortality relationship is the same across all years (**Complete pooling**, 2 params)
* **Hypothesis 2**: The *average survival* varies by year, but the slope between precipitation and mortality is constant (**Unpooled intercepts, pooled slopes**, 17 params)
    - Sample size by year ranges from 1 to 208
::::
:::: {.column}
```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, 
						p+-a1989, p+-"a1994...", p+-"...a2012",
						p+-b, p+-precip, 
						a1989+-"μ_a=0", a1989+-"σ_a=10", 
						"a1994..."+-"μ_a=0", "a1994..."+-"σ_a=10",
						"...a2012"+-"μ_a=0", "...a2012"+-"σ_a=10",
						b+-"μ_b=0", b+-"σ_b=5")
V(gr)$type = c("random", "deterministic", "deterministic", 
			   rep("random", 4), rep("deterministic", 5))
V(gr)$source = c("known", "unknown", "known", rep("unknown", 4), rep("known", 5))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  
				  c(-0.5,1) + c(-0.1,0, 0,0, 0.1,0),  
				  0.5, 1,  0.5, 1.8, -0.75,0, -0.25,0,  0.25,0,  0.75,0), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_slpool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = -0.1, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.5, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5) + ggtitle("Pooled Slopes")
grpl_slpool
```
::::
:::



## Precipitation-mortality relationships in Tsuga: H3

::: {.columns}
:::: {.column}
* **Question:** Does mortality of *Tsuga canadensis* vary with precipitation?
	- The species generally prefers moist conditions
* **Hypothesis 1**: The precipitation-mortality relationship is the same across all years (**Complete pooling**, 2 params)
* **Hypothesis 2**: The *average survival* varies by year, but the slope between precipitation and mortality is constant (**Unpooled intercepts, pooled slopes**, 17 params)
    - Sample size by year ranges from 1 to 208
* **Hypothesis 3**: There is a different regression line for each year (**No pooling**, 32 parameters)

::::
:::: {.column}
```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, 
						p+-a1989, p+-"a1994...", p+-"...a2012",
						p+-b1989, p+-"b1994...", p+-"...b2012",
						p+-precip, 
						a1989+-"μ_a=0", a1989+-"σ_a=10", 
						"a1994..."+-"μ_a=0", "a1994..."+-"σ_a=10",
						"...a2012"+-"μ_a=0", "...a2012"+-"σ_a=10",
						b1989+-"μ_b=0", b1989+-"σ_b=5", 
						"b1994..."+-"μ_b=0", "b1994..."+-"σ_b=5",
						"...b2012"+-"μ_b=0", "...b2012"+-"σ_b=5")
V(gr)$type = c("random", "deterministic", "deterministic", 
			   rep("random", 6), rep("deterministic", 5))
V(gr)$source = c("known", "unknown", "known", rep("unknown", 6), rep("known", 5))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  
				  c(-0.5,1) + c(-0.1,0, 0,0, 0.1,0), c(0.5,1) + c(-0.1,0, 0,0, 0.1,0),  
				  0.5, 1.8, -0.75,0, -0.25,0,  0.25,0,  0.75,0), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_nopool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = -0.1, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.5, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5) + ggtitle("No Pooling")
grpl_nopool
```
::::
:::

## Pooled model code
::: {.columns}
:::: {.column}
```{r eval = FALSE}
# compile the model (below)
tsuga_pooled = stan_model("stan/tsuga_pooled.stan")
```

```{r eval = FALSE}
	```{stan file = "../stan/tsuga_pooled.stan", output.var="tsuga_pooled", cache = TRUE}
```


::::
:::: {.column}
```{r, cache = TRUE}
## Fit the model
## note that I have rescaled precipitaiton
## additionally, we add the year variable as a factor
precip = scale(tsuga$tot_annual_pp) 
standat = with(tsuga, list(
	n = length(died),
	n_trees = n,
	died = died,
	precip = precip[,1],
	year = as.factor(year)))  
fit_pooled = sampling(tsuga_pooled, chains=4, iter=3000, refresh=0, data = standat)
```
::::
:::

## Pooled models trade accuracy for precision

* All data for a single set of estimates
	- highly precise parameter estimates

```{r plotfuns, echo = FALSE}
prob_ci = function(pr, data) {
	quants = apply(pr, 2, quantile, c(0.5, 0.05, 0.95))
	data.table(pr_obs = data$died/data$n_trees, pred = quants[1,], 
						lower = quants[2,], upper = quants[3,],
						year = as.factor(tsuga$year))
}
obs_pred_plot = function(probci) {
	ggplot(probci, aes(x=pr_obs, y = pred, colour=year)) + geom_point() + 
		geom_abline(intercept=0, slope=1, lty=2) + 
		geom_errorbar(aes(x=pr_obs, ymin=lower, ymax=upper, width=0)) + 
		theme_minimal() + xlim(0,1) + ylim(0,1) + 
		xlab("Observed proportion surviving") + ylab("Predicted proportion surviving")
}
# compute errors
# squared error per data point
rmse_tsuga = function(probs, data) {
	se_sample = sweep(probs, 2, data$died/data$n_trees, `-`)^2
	rmse_year = apply(se_sample, 1, \(x) tapply(x, data$year, \(y) sqrt(mean(y))))
	rmse_year = t(apply(rmse_year, 1, quantile, c(0.5, 0.05, 0.95)))
	rmse_year_dt = data.table(rmse_year)
	colnames(rmse_year_dt) = c("rmse", "lower", "upper")
	rmse_year_dt$year = rownames(rmse_year)
	rmse_year_dt$n = as.vector(table(data$year))
	rmse_year_dt
}
err_plot = function(errdt) {
	ggplot(errdt, aes(x = year, y = rmse, colour=n)) + geom_point() + 
		geom_errorbar(aes(x = year, ymin=lower, ymax=upper, width=0)) + 
		theme_minimal() + scale_colour_viridis_c(option="magma") + ylab("Mean Prediction Error")
}
rc_plot = function(samp) {
	xx = seq(min(precip), max(precip), length.out=200)
	pred = apply(samp, 1, \(par) plogis(par[1] + par[2] * xx))
	quants = t(apply(pred, 1, quantile, c(0.5, 0.05, 0.95)))
	colnames(quants) = c("pr", "lower", "upper")
	pldat = data.table(quants)
	pldat$x = xx * attr(precip, "scaled:scale") + attr(precip, "scaled:center")
	ggplot(pldat, aes(x = x, y = pr)) +geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.5) + 
		geom_line(col='blue') + ylim(0, 1) + theme_minimal() + 
		xlab("Precipitation") + ylab("pr(death)")
}
```

```{r, cache = TRUE, echo = FALSE, fig.width=15}
probs = as.matrix(fit_pooled, pars='p')
par_samples = as.matrix(fit_pooled, pars=c("a", "b"))
ci_pooled = prob_ci(probs, standat)
errs = rmse_tsuga(probs, standat)
pl_probs_pooled = obs_pred_plot(ci_pooled)
pl_err_pooled = err_plot(errs)
pl_intervals_pooled = mcmc_intervals(par_samples) + theme_minimal()
rc = rc_plot(par_samples)

grid.arrange(pl_intervals_pooled, rc, ncol=2)
```


## Pooled models trade accuracy for precision

* All data for a single set of estimates
	- highly precise parameter estimates
* High prediction errors for individual groups 
* Groups with small samples biased towards the mean

```{r, cache = TRUE, echo = FALSE, fig.width=15}
grid.arrange(pl_probs_pooled, pl_err_pooled, ncol=2)
```


## Unpooled model: code

::: {.columns}
:::: {.column}
```{r eval = FALSE}
# compile the model (below)
tsuga_unpooled = stan_model("stan/tsuga_unpooled.stan")
```

```{stan file = "../stan/tsuga_unpooled.stan", output.var="tsuga_unpooled", cache = TRUE}
```

::::
:::: {.column}
```{r}
# factor variables must be converted to integers for stan
standat$year_id = as.integer(standat$year)

# we also need to tell stan how many groups (i.e., years) there are
standat$n_groups = max(standat$year_id)
```

```{r, echo = FALSE}
# here is what the different levels for year_id look like
yeartab = unique(cbind(
	year = as.integer(as.character(standat$year)),
	year_int = standat$year_id
))
# sorted by year
head(yeartab[order(yeartab[,1]),])
```

```{r, eval = FALSE}
fit_unpooled = sampling(tsuga_unpooled, chains=4, iter=3000, refresh=0, 
						data = standat)
```

```{r, cache = TRUE, echo = FALSE, results = 'hide'}
## done in two blocks to hide rstan warnings
## saved here, locally cached file, recreate by running the block above
fit_unpooled = readRDS("misc/7_tsuga_unpooled.rds")
```


::::
:::


## Unpooled models use less data per parameter

```{r, cache = TRUE, echo = FALSE, fig.width=15}

rc_plot_year = function(samp) {
	yearnames = sort(as.integer(as.character(levels(standat$year))))
	yearids = c(1, 7, 8, 16)
	xx = seq(min(precip), max(precip), length.out=200)
	pldat = lapply(yearids, \(yid) {
		pred = apply(samp, 1, \(par) plogis(par[yid] + par[max(yearids)+1] * xx))
		quants = t(apply(pred, 1, quantile, c(0.5, 0.05, 0.95)))
		colnames(quants) = c("pr", "lower", "upper")
		pldat = data.table(quants)
		pldat$x = xx * attr(precip, "scaled:scale") + attr(precip, "scaled:center")
		pldat$year = yearnames[yid]
		pldat
	})
	pldat = rbindlist(pldat)
	pldat$year = as.factor(pldat$year)
	
	ggplot(pldat, aes(x = x, y = pr, colour = year)) + 
		geom_ribbon(aes(ymin = lower, ymax = upper, fill = year), alpha = 0.3) + 
		geom_line() + ylim(0, 1) + theme_minimal() + 
		xlab("Precipitation") + ylab("pr(death)")
}

probs = as.matrix(fit_unpooled, pars='p')
par_samples = as.matrix(fit_unpooled, pars=c("a", "b"))
ci_unpooled = prob_ci(probs, standat)
errs = rmse_tsuga(probs, standat)
pl_probs_unpooled = obs_pred_plot(ci_unpooled)
pl_err_unpooled = err_plot(errs)
pl_intervals_unpooled = mcmc_intervals(par_samples) + theme_minimal()
rc = rc_plot_year(par_samples)

grid.arrange(pl_intervals_unpooled, rc, ncol=2)
```



## Unpooled models use less data per parameter

* Very imprecise, especially for groups with few samples
* Prediction to new groups (years) impossible

```{r, cache = TRUE, echo = FALSE, fig.width=15}
grid.arrange(pl_probs_unpooled, pl_err_unpooled, ncol=2)
```




## Compromise: partial pooling
::: {.columns}
:::: {.column}

* We don't really expect each year to be independent
    - it's all one species, response to temperature should be similar
    - some years are better or worse than others
* Imagine instead there is a population of possible years, each with its own mortality
* This population has a true mean and a true variance
* The samples we've taken will come from that distribution
* This can tell us something about all possible years, not just these years


::::
:::: {.column}


```{r, echo = FALSE, fig.width=8}


gr = graph_from_literal(died+-p, died+-N, 
						p+-a1989, p+-"a1994...", p+-"...a2012",
						p+-b1989, p+-"b1994...", p+-"...b2012",
						p+-precip, 
						a1989+-"μ_a", a1989+-"σ_a", 
						"a1994..."+-"μ_a", "a1994..."+-"σ_a",
						"...a2012"+-"μ_a", "...a2012"+-"σ_a",
						b1989+-"μ_b", b1989+-"σ_b", 
						"b1994..."+-"μ_b", "b1994..."+-"σ_b",
						"...b2012"+-"μ_b", "...b2012"+-"σ_b", 
						"μ_a"+-"Normal(0,20)", "σ_a"+-"Half Cauchy(0, 20)",
						"μ_b"+-"Normal(0,20)", "σ_b"+-"Half Cauchy(0, 20)")
V(gr)$type = c("random", "deterministic", "deterministic", 
			   rep("random", 6), "deterministic", rep("random", 4), rep("deterministic", 2))
V(gr)$source = c("known", "unknown", "known", rep("unknown", 6), "known", rep("unknown", 4), rep("known", 2))
layout = matrix(NA, nrow = length(V(gr)), ncol = 2)
#			   died, p,   N,    a...,           b...,        precip, hyper_a,      hyper_b,    prior
layout[,1] = c(0,    0,   -0.5, -0.6,-0.5,-0.4, 0.4,0.5,0.6, 0.5,    -0.75, -0.25, 0.25, 0.75,  -0.25, 0.25)
layout[,2] = c(2,    1.2, 1.8,  rep(1, 6),                   1.8,    rep(0, 4),                rep(-1, 2))
nt = ggnetwork(gr, layout=layout)
grpl_ppool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = 0, label = "Hyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.3, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.67, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5) + ggtitle("Partial Pooling")
grpl_ppool
```


::::
:::


## Partial Pooling: Code

::: {.columns}
:::: {.column}
```{r eval = FALSE}
# compile the model (below)
tsuga_ppool = stan_model("stan/tsuga_ppool.stan")
```

```{r eval = FALSE}
	```{stan file = "../stan/tsuga_ppool.stan", output.var="tsuga_ppool", cache = TRUE}
```

::::
:::: {.column}

```{r cache = TRUE}
fit_ppool = sampling(tsuga_ppool, chains=4, iter=3000, refresh=0, 
						data = standat)
```


::::
:::



## Partial pooling is a compromise

* for a given group, we combine the information for this group with information from all groups
* balances precision and accuracy
* can be best approach for new groups
* weak/undersampled groups can "borrow strength" from others

```{r, cache = TRUE, echo = FALSE, fig.width=15}
rc_plot_year_slope = function(samp) {
	yearnames = sort(as.integer(as.character(levels(standat$year))))
	yearids = c(1, 7, 8, 16)
	xx = seq(min(precip), max(precip), length.out=200)
	pldat = lapply(yearids, \(yid) {
		pred = apply(samp, 1, \(par) plogis(par[yid] + par[max(yearids)+yid] * xx))
		quants = t(apply(pred, 1, quantile, c(0.5, 0.05, 0.95)))
		colnames(quants) = c("pr", "lower", "upper")
		pldat = data.table(quants)
		pldat$x = xx * attr(precip, "scaled:scale") + attr(precip, "scaled:center")
		pldat$year = yearnames[yid]
		pldat
	})
	pldat = rbindlist(pldat)
	pldat$year = as.factor(pldat$year)
	
	ggplot(pldat, aes(x = x, y = pr, colour = year)) + 
		geom_ribbon(aes(ymin = lower, ymax = upper, fill = year), alpha = 0.3) + 
		geom_line() + ylim(0, 1) + theme_minimal() + 
		xlab("Precipitation") + ylab("pr(death)")
}

probs = as.matrix(fit_ppool, pars='p')
par_samples = as.matrix(fit_ppool, pars=c("a", "b"))
ci_ppool = prob_ci(probs, standat)
errs = rmse_tsuga(probs, standat)
pl_probs_ppool = obs_pred_plot(ci_ppool)
pl_err_ppool = err_plot(errs)
pl_intervals_ppool = mcmc_intervals(par_samples) + theme_minimal()
rc = rc_plot_year_slope(par_samples)

grid.arrange(pl_intervals_ppool, rc, ncol=2)
```


## Partial pooling is a compromise
```{r, cache = TRUE, echo = FALSE, fig.width=15}
grid.arrange(pl_probs_ppool, pl_err_ppool, ncol=2)
```





## Pooling comparison
```{r echo = FALSE, fig.width=18}
grid.arrange(pl_err_pooled + ggtitle("Pooled") + ylim(0, 0.9), 
			 pl_err_unpooled + ggtitle("Unpooled") + ylim(0, 0.9), 
			 pl_err_ppool + ggtitle("Partially Pooled") + ylim(0, 0.9), ncol=3)
```

## Pooling comparison
```{r echo = FALSE, fig.width=18}
grid.arrange(pl_intervals_pooled + ggtitle("Pooled"), 
			 pl_intervals_unpooled + ggtitle("Unpooled"), 
			 pl_intervals_ppool + ggtitle("Partially Pooled"), ncol=3)
```


## When do we need hierarchical models?
* Repeated sampling within units (e.g., samples nested within plots/individuals)
* Inference at multiple levels of organisation
    - Covariates at multiple spatial scales
* Uneven sampling among units
* Accounting for nonindependence of samples
* Avoiding pre-averaging
    - Don't: perform repeat samples on a unit, perform analysis on the average
    - Do: Build an HM accounting for variability within and among units
* A common category of HM is often called mixed modeling
    - All mixed models are hierarchical, not all hierarchical models are mixed models



## Designing hierarchical models in Stan
::: {.columns}
:::: {.column}
* You must specify data/objects at all levels
* Often we use an indexing variable to link observations to their group
* This variable **must** start at 1 and end at *n_groups*

::::
:::: {.column}
```{stan output.var="stan_hm", eval = FALSE}
data {
	// group-level objects
	int <lower=1> n_groups;
	int <lower=1, upper=n_groups> group_id [n];
}
parameters {
	vector [n_groups] a; 
	
	// hyperparameters
	real a_mu;
	real a_sig;
}
transformed parameters {
	pr[i] = inv_logit(a[group_id[i]]);
}
model {
	a ~ normal(a_mu, a_sig);  // hierarchical prior for a
}
```
::::
:::


## Designing hierarchical models in Stan
::: {.columns}
:::: {.column}
* You must specify data/objects at all levels
* Often we use an indexing variable to link observations to their group
* This variable **must** start at 1 and end at *n_groups*
* Multiple non-nested groups are possible



```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, p+-precip,
						p+-a1_n, p+-a2_n, p+-b,
						a1_n+-"μ_a1", a1_n+-"σ_a1", 
						a2_n+-"μ_a2", a2_n+-"σ_a2",
						b+-"μ_b=0", b+-"σ_b=5", 
						"μ_a1"+-"N(0,10)", "σ_a1"+-"G(0.1,0.1)",
						"μ_a2"+-"N(0,10)", "σ_a2"+-"G(0.1,0.1)")
V(gr)$type = c("random", rep("deterministic", 3), rep("random", 7), rep("deterministic", 4))
V(gr)$source = c("known", "unknown", rep("known", 2), rep("unknown", 7), rep("known", 4))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  0.5,1.8,
				  -0.5,1,  -1,1,  0.5,1,  
				   -0.7,0, -0.3,0,  -1.2,0, -0.8,0,  0.25,0,  0.75,0,  -0.8,-1, -0.3,-1), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_hm1 = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = 0, label = "Hyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.3, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.67, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5)
grpl_hm1
```





::::
:::: {.column}
```{stan output.var="stan_hm", eval = FALSE}
data {
	int n; // number of data points
	int died [n]
	int N[n];
	vector [n] precip;

	// group-level objects
	int <lower=1> n_group1;
	int <lower=1, upper=n_group1> group1_id [n];

	int <lower=1> n_group2;
	int <lower=1, upper=n_group2> group2_id [n];
}
parameters {
	vector [n_group1] a1; 
	vector [n_group2] a2; 
	
	// hyperparameters
	real a1_mu;
	real <lower=0> a1_sig;
	real a2_mu;
	real <lower=0> a2_sig;
}
transformed parameters {
	vector [n] pr;
	for(i in 1:n)
		pr[i] = inv_logit(a1[group1_id[i]] + a2[group2_id[i]] + b*precip[i]);
}
model {
	died ~ binomial(N, pr); // likelihood

	a1 ~ normal(a1_mu, a1_sig);  // hierarchical prior for a1
	a2 ~ normal(a2_mu, a2_sig);  // hierarchical prior for a2

	// hyperpriors
	a1_mu ~ normal(0,10)
	a2_mu ~ normal(0,10)
	a1_sig ~ gamma(0.1, 0.1);
	a2_sig ~ gamma(0.1, 0.1);
}
```

::::
:::





## Designing hierarchical models in Stan
::: {.columns}
:::: {.column}
* Nested groups add an additional hierarchical layer


```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, p+-precip,
						p+-a1_n, a1_n+-a2_n, p+-b,
						a1_n+-"σ_a1", 
						a2_n+-"μ_a2", a2_n+-"σ_a2",
						b+-"μ_b=0", b+-"σ_b=5", 
						"σ_a1"+-"G(0.1,0.1)",
						"μ_a2"+-"N(0,10)", "σ_a2"+-"G(0.1,0.1)")
V(gr)$type = c("random", rep("deterministic", 3), rep("random", 6), rep("deterministic", 4))
V(gr)$source = c("known", "unknown", rep("known", 2), rep("unknown", 6), rep("known", 4))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  0.5,1.8,
				  -0.5,1,  -0.75,0,  0.5,1,  
				   -0.3,0,  -1,-1, -0.5,-1, 0.25,0,  0.75,0,  -0.1,-1.2, -1,-2), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_hm2 = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = 0, label = "Hyperhyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.25, label = "Hyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.5, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.75, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5)
grpl_hm2
```


::::
:::: {.column}
```{stan output.var="stan_hm", eval = FALSE}
data {
	int n; // number of data points
	int died [n]
	int N[n];
	vector [n] temperature;

	// group-level objects
	int <lower=1> n_group1;
	int <lower=1, upper=n_group1> group1_id [n];

	int <lower=1> n_group2;
	int <lower=1, upper=n_group2> group2_id [n_group1];
}
parameters {
	vector [n_group1] a1; 
	vector [n_group2] a2; 
	
	// hyperparameters
	real <lower=0> a1_sig;
	real a2_mu;
	real <lower=0> a2_sig;
}
transformed parameters {
	vector [n] pr;
	for(i in 1:n)
		pr[i] = inv_logit(a1[group1_id[i]] + b*precip[i]);
}
model {
	died ~ binomial(N, pr); // likelihood

	for(i in n_group1)
		a1 ~ normal(a2[i], a1_sig);  // hierarchical prior for a1
	// hyperpriors
	a2 ~ normal(a2_mu, a2_sig);  // hierarchical prior for a2
	a1_sig ~ gamma(0.1, 0.1);
	
	// hyperhyperprior
	a2_mu ~ normal(0,10)
}
```
::::
:::




## Posterior predictive distributions
::: {.columns}
:::: {.column}
* Do we want to predict new observations from a known group? 
	- e.g: What is the PPD for trees in 1989?
    - Use **generated quantities** block in Stan
* Or new observations from an unknown group?
    - Simulate new values for each param, drawn from hyper params
    - Then simulate the individual observations

::::
:::: {.column}

```{r}
sim1 = function(amu, asig, bmu, bsig, N, precip) {
	a = rnorm(length(precip), amu, asig)
	b = rnorm(length(precip), bmu, bsig)
	p = plogis(a + b*precip)
	rbinom(length(precip), N, p)
}
```
::::
:::



## Posterior predictive distributions
::: {.columns}
:::: {.column}
```{r cache=TRUE}
newx = seq(min(standat$precip), max(standat$precip), length.out=400)
pars = data.frame(as.matrix(fit_ppool, pars=c("a_mu", "a_sig", "b_mu", "b_sig")))

# For our hypothetical, we need to decide how many trees we would see
# more trees means less sampling uncertainty
N = 20
sims = mapply(sim1, amu = pars$a_mu, asig = pars$a_sig,
			  bmu = pars$b_mu, bsig = pars$b_sig, 
			  MoreArgs = list(N = 20, precip = newx))
sim_quantiles = apply(sims, 1, quantile, c(0.5, 0.05, 0.95))
```

::::
:::: {.column}


```{r echo = FALSE}
sim_qs = data.frame(t(sim_quantiles)/N)
colnames(sim_qs) = c("died", "lower", "upper")
## undo the scaling so we can see the plot on the original scale
sim_qs$precip = (newx * sd(tsuga$tot_annual_pp)) + mean(tsuga$tot_annual_pp)
ggplot(sim_qs, aes(x = precip, y = died)) + 
	geom_ribbon(aes(ymin = lower, ymax = upper), fill = cols[1], alpha = 0.4) + 
	geom_line(col = cols[1], linewidth = 0.8) + 
	theme_minimal() + xlab("Total Annual Precipitation(mm)") + 
	ylab("Predicted Proportion Dead") + ylim(0, 1)
```
::::
:::
