---
title: "Hierarchical Models"
author: "M. Talluto"
date: "01.12.2023"
output:
  slidy_presentation:
    theme: cerulean
    toc_depth: 2
    css: rmd_style.css
    self_contained: false
    lib_dir: lib
  beamer_presentation: default
---

```{r setup, include=FALSE, results = "hide"}
# knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.width=8, fig.height=5.5, collapse = TRUE, comment = "##", dev="png", error=TRUE)

library(ggplot2)
library(sf)
library(rstan)
library(bayesplot)


library(igraph)
library(ggnetwork)
library(data.table)
library(gridExtra)

cols = c("#F8766D", "#7CAE00", "#00BFC4", "#C77CFF")
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)

```

## Kidney cancer death rates in the US
::: {.columns}
:::: {.column}

* Kidney cancer death rates in the US, by county
* Is there a geographic pattern? If so, why?

:::: {.small}
Data source: Gelman et al. 2004. [Bayesian Data Analysis](http://www.stat.columbia.edu/~gelman/book/).
::::

::::
:::: {.column}

```{r cancer_map, cache = TRUE, echo = FALSE, message = FALSE}
invisible(capture.output(counties <- st_read("../vu_advstats_students/data/us_k_cancer_spatial.gpkg")))

pl_cancer = ggplot(counties) + 
	geom_sf(aes(fill = death_rate_per_1000, colour = death_rate_per_1000)) + 
	scale_fill_viridis_c("Death rate", option = "rocket") + 
	scale_colour_viridis_c("Death rate", option = "rocket")
pl_cancer
```

::::
:::

## Kidney cancer death rates in the US
::: {.columns}
:::: {.column}

* Kidney cancer death rates in the US, by county
* Is there a geographic pattern? If so, why?

::::
:::: {.column}

```{r cancer_quantile_map, cache = TRUE, echo = FALSE, message = FALSE}

cols = c("#e31a1c", "#1f78b4", "#ffffff")
pl_c_quantile = ggplot(counties) + 
	geom_sf(aes(fill = factor(quantile)), colour = "#555555", linewidth = 0.2) + 
	scale_discrete_manual("Quantile", aesthetics = "fill", values = cols)

pl_c_quantile
```

::::
:::


## Kidney cancer death rates in the US
::: {.columns}
:::: {.column}

* Kidney cancer death rates in the US, by county
* Is there a geographic pattern? If so, why?
* How can we estimate county-specific rates in a reasonable way?

```{r pop_map, cache = TRUE, echo = FALSE, message = FALSE, warning=FALSE}

ggplot(counties) + 
	geom_sf(aes(fill = population, colour = population)) + 
	scale_fill_viridis_c("Population size", option = "magma", trans = "log10") + 
	scale_colour_viridis_c("Population size", option = "magma", trans = "log10")

```

::::
:::: {.column}

```{r cancer_quantile_combo, cache = TRUE, echo = FALSE, message = FALSE, fig.height = 8}
grid.arrange(pl_cancer, pl_c_quantile, ncol = 1)
```

::::
:::


## Kidney cancer Stan model: global/constant rate
::: {.columns}
:::: {.column}

* Our data are counts, suggesting Poisson
	- We don't use binomial in part because we care about death **rate**, not probability
* Here we build a model accounting for **exposure** (population size)
* We assume mortality rate $\lambda$ is constant for the entire dataset
	- $\lambda$ is **pooled** across units (county)


::::
:::: {.column}

```{r cancer_data, message = FALSE}
library(data.table)
(cancer = readRDS("../vu_advstats_students/data/us_k_cancer.rds"))
```

::::
:::




## Kidney cancer Stan model: global/constant rate
::: {.columns}
:::: {.column}

* Our data are counts, suggesting Poisson
	- We don't use binomial in part because we care about death **rate**, not probability
* Here we build a model accounting for **exposure** (population size)
* We assume mortality rate $\lambda$ is constant for the entire dataset
	- $\lambda$ is **pooled** across units (county)


::::
:::: {.column}


```{stan stan_cancer_pooled, cache = TRUE, output.var = "cancer_pooled"}
data {
	int <lower = 1> n;
	int <lower = 0> deaths [n];
	int <lower = 0> population [n];
	real <lower = 0> alpha;
	real <lower = 0> beta;
}
transformed data {
	// cancer is rare, lets make the numbers more reasonable
	vector <lower = 0> [n] exposure;
	for(i in 1:n)
		exposure[i] = population[i] / 1000.0;
}
parameters {
	real <lower = 0> lambda;
}
model {
	deaths ~ poisson(exposure * lambda);
	lambda ~ gamma(alpha, beta);
}
```

::::
:::




## Kidney cancer Stan model: global/constant rate
::: {.columns}
:::: {.column}

* Our data are counts, suggesting Poisson
	- We don't use binomial in part because we care about death **rate**, not probability
* Here we build a model accounting for **exposure** (population size)
* We assume mortality rate $\lambda$ is constant for the entire dataset
	- $\lambda$ is **pooled** across units (county)
	- Interpretation of $\lambda$: cancer deaths per five years per 1000 people
	
**Question**: Is there geographic variation in cancer rates?


::::
:::: {.column}

```{r cancer_pooled_compile, eval = FALSE}
library(rstan)
cancer_pooled = stan_model("stan/kidney_cancer_pooled.stan")
```

```{r fit_cancer_pooled, cache = TRUE}
cancer = cancer[complete.cases(cancer)]
cancer_data_stan = list(
	n = nrow(cancer),
	deaths = cancer$kidney_cancer_deaths,
	population = cancer$population,
	alpha = 0.01, # extremely vague priors, probably too vague!
	beta = 0.01
)
cancer_p_fit = sampling(cancer_pooled, data = cancer_data_stan, refresh = 0)
quantile(as.matrix(cancer_p_fit, pars = "lambda")[,1], c(0.05, 0.95))
```

::::
:::






## Kidney cancer Stan model: rates per county

::: {.columns}
:::: {.column}

* We assume mortality rate $\lambda$ is independent for each county
	- $\lambda$ is **unpooled** across units (county)
* This model has a lot of parameters, and doesn't fit well
* Max of 2 observations per lambda!


::::
:::: {.column}


```{stan stan_cancer_unpooled, output.var = "cancer_unpooled", eval = FALSE}
data {
	int <lower = 1> n;
	int <lower = 1> n_counties;
	int <lower = 0> deaths [n];
	int <lower = 0> population [n];
	int <lower = 0, upper = n_counties> county_id [n];
	real <lower = 0> alpha;
	real <lower = 0> beta;
}
transformed data {
	// cancer is rare, lets make the numbers more reasonable
	vector <lower = 0> [n] exposure;
	for(i in 1:n)
		exposure[i] = population[i] / 1000.0;
}
parameters {
	vector <lower = 0> [n_counties] lambda;
}
model {
	for(i in 1:n) {
		int j = county_id[i];
		deaths[i] ~ poisson(exposure[i] * lambda[j]);
	}
	lambda ~ gamma(alpha, beta);
}
```

::::
:::



## Kidney cancer Stan model: partial pooling

::: {.columns}
:::: {.column}

* We can use the overall rate for the whole country as a prior for individual counties
* Areas with few observations will use the whole country as a slight reality check
* $\lambda$ is **partially pooled**

```{r, echo = FALSE, fig.width=8, warning = FALSE}
gr = graph_from_literal(deaths+-lambda, lambda+-alpha, lambda+-beta, deaths+-exposure, alpha+-aa, alpha+-ba, 
						beta+-ab, beta+-bb)
V(gr)$type = c(rep("random", 4), rep("deterministic", 5))
V(gr)$source = c("known", rep("unknown", 3), rep("known", 5))

layout = rbind(deaths = c(0, 3), lambda = c(0, 2), alpha = c(-0.5, 1), beta = c(0.5, 1), 
			   exposure = c(0.5, 3), alpha_a = c(-0.75, 0), beta_a = c(-0.25, 0), 
			   alpha_b = c(0.25, 0), beta_b = c(0.75, 0))

n = ggnetwork(gr, layout=layout)
nlabs = c(expression(alpha[alpha]), expression(alpha), expression(beta[alpha]), expression(lambda), 
		  expression(alpha[beta]), expression(beta), "exposure", expression(beta[beta]), "deaths")

grpl_pool = ggplot(n, aes(x = x, y = y, xend = xend, yend = yend)) + 
	geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), 
			type = "closed")) + 
	theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
	geom_nodelabel(label = nlabs, fontface = "bold", nudge_x=-0.1) +
	annotate(geom = "label", x = 1.3, y = 1, label = "Data") +
	annotate(geom = "label", x = 1.3, y = 0.67, label = "Parameters") +
	annotate(geom = "label", x = 1.3, y = 0.33, label = "Priors/Hyperparameters") +
	annotate(geom = "label", x = 1.3, y = 0, label = "Hyper-Hyperparameters") +
	xlim(-0.1, 1.6)
grpl_pool


```

::::
:::: {.column}


```{stan stan_cancer_ppooled, cache = TRUE, output.var = "cancer_ppooled"}
data {
	int <lower = 1> n;
	int <lower = 1> n_counties;
	int <lower = 0> deaths [n];
	int <lower = 0> population [n];
	int <lower = 0, upper = n_counties> county_id [n];

	// hyper-hyper parameters, for the hyperprior
	real <lower = 0> a_alpha;
	real <lower = 0> a_beta;
	real <lower = 0> b_alpha;
	real <lower = 0> b_beta;
}
transformed data {
	// cancer is rare, lets make the numbers more reasonable
	vector <lower = 0> [n] exposure;
	for(i in 1:n)
		exposure[i] = population[i] / 1000.0;
}
parameters {
	vector <lower = 0> [n_counties] lambda;
	
	// prior hyperparameters for lambda are now parameters we will estimate!
	real <lower = 0> alpha;
	real <lower = 0> beta;
	
}
model {
	for(i in 1:n) {
		int j = county_id[i];
		deaths[i] ~ poisson(exposure[i] * lambda[j]);
	}
	
	// prior for lambda
	lambda ~ gamma(alpha, beta);
	
	// hyperpriors for alpha and beta
	alpha ~ gamma(a_alpha, a_beta);
	beta ~ gamma(b_alpha, b_beta);
}
generated quantities {
	// save the overal mean and variance in cancer rate
	real lambda_mu = alpha/beta;
	real lambda_var = alpha/beta^2;
}
```

::::
:::





## Kidney cancer Stan model: partial pooling
::: {.columns}
:::: {.column}

* We can use the overall rate for the whole country as a prior for individual counties
* Areas with few observations will use the whole country as a slight reality check
* $\lambda$ is **partially pooled**
* Parameters with limited information can **borrow strength** from the rest of the dataset
* We must take care when choosing the hyperprior parameters
	- this cancer is rare, less than one per 1000 on average
	- we choose a range for alpha and beta that is wide, but makes mostly impossible values very unlikely

::::
:::: {.column}

```{r cancer_ppooled_priors, cache = TRUE}
mean(cancer$death_rate_per_1000/(cancer$population/1000))
sd(cancer$death_rate_per_1000/(cancer$population/1000))
alpha_a = 0.01
beta_a = 1

# our hyperparameter alpha has a 99% prob of being between these two values
(a_int = qgamma(c(0.01, 0.99), alpha_a, beta_a))

alpha_b = 0.8
beta_b = 0.4
# our hyperparameter alpha has a 99% prob of being between these two values
(b_int = (round(qgamma(c(0.01, 0.99), alpha_b, beta_b), 2)))

## what would the mean lambda look like at these extremes?
round(matrix(c(a_int[1] / b_int[1], a_int[2]/b_int[1], a_int[1] / b_int[2], a_int[2] / b_int[2]), nrow = 2, 
	   dimnames = list(c("min a", "max a"), c("min b", "max b"))),2)

cancer_data_stan$a_alpha = alpha_a
cancer_data_stan$b_alpha = alpha_b
cancer_data_stan$a_beta = beta_a
cancer_data_stan$b_beta = beta_b
```

::::
:::




## Kidney cancer Stan model: partially pooled rates per county
::: {.columns}
:::: {.column}

* We can use the overall rate for the whole country as a prior for individual counties
* Areas with few observations will use the whole country as a slight reality check
* $\lambda$ is **partially pooled**
* Parameters with limited information can **borrow strength** from the rest of the dataset
* We must take care when choosing the hyperprior parameters
	- this cancer is rare, less than one per 1000 on average
	- we choose a range for alpha and beta that is wide, but makes mostly impossible values very unlikely

::::
:::: {.column}


```{r cancer_ppooled_compile, eval = FALSE}
library(rstan)
cancer_unpooled = stan_model("stan/kidney_cancer_ppooled.stan")
```

```{r fit_cancer_ppooled, cache = TRUE}
cancer$county_id = as.integer(factor(cancer$county))
cancer_data_stan$county_id = cancer$county_id
cancer_data_stan$n_counties = max(cancer$county_id)

cancer_ppool_fit = sampling(cancer_ppooled, data = cancer_data_stan, refresh = 0, iter = 5000)
cancer_ppool_samps = as.matrix(cancer_ppool_fit, pars = "lambda")
quants = t(apply(cancer_ppool_samps , 2, quantile, c(0.05, 0.95)))
head(quants)

# quantile interval for the overall mean
round(rbind(pooled = quantile(as.matrix(cancer_p_fit, pars = "lambda"), c(0.05, 0.95)),
	partial_pooled = quantile(as.matrix(cancer_ppool_fit, pars = "lambda_mu"), c(0.05, 0.95))), 4)
```



::::
:::




## Kidney cancer Stan model: partially pooled maps

``` {r cancer_fit_maps, echo = FALSE, cache = TRUE, fig.width = 12}
lam_med = apply(cancer_ppool_samps, 2, median)
lam_sd = apply(cancer_ppool_samps, 2, sd)
cancer_flat = unique(cancer[,.(state, county, county_id)])

cancer_flat$cancer_rate_fit = lam_med[cancer_flat$county_id]
cancer_flat$cancer_rate_se = lam_sd[cancer_flat$county_id]

counties = merge(counties, cancer_flat, by = c("state", "county"), all.x = TRUE)
pl_c_death_fit = ggplot(counties) + geom_sf(aes(fill = cancer_rate_fit, colour = cancer_rate_fit)) + 
	scale_fill_viridis_c("Death rate", option = "rocket") + 
	scale_colour_viridis_c("Death rate", option = "rocket") + 
	ggtitle("Kidney Cancer Rate (Hierarchical Model)")

pl_c_death_sd = ggplot(counties) + geom_sf(aes(fill = cancer_rate_se, colour = cancer_rate_se)) + 
	scale_fill_viridis_c("Death rate", option = "inferno") + 
	scale_colour_viridis_c("Death rate", option = "inferno") + 
	ggtitle("Kidney Cancer Rate Standard Error (Hierarchical Model)")

counties$new_quantile = with(counties, cut(cancer_rate_fit, 
				breaks = quantile(cancer_rate_fit, c(0, 0.1, 0.9, 1), na.rm = TRUE), 
				labels = c("Lowest 10%", "Middle", "Highest 10%")))
pl_c_quantile_fit = ggplot(counties) + 
	geom_sf(aes(fill = factor(new_quantile)), colour = "#555555", linewidth = 0.2) + 
	scale_discrete_manual("Quantile", aesthetics = "fill", values = cols[c(2, 3, 1)]) + 
	ggtitle("Kidney Cancer Quantiles (Hierarchical Model)")

grid.arrange(pl_c_death_fit, pl_c_death_sd, nrow = 1)
```

## Kidney cancer Stan model: partially pooled maps

``` {r cancer_fit_maps2, echo = FALSE, cache = TRUE, fig.width = 12}
grid.arrange(pl_c_quantile_fit, pl_c_quantile + ggtitle("Kidney Cancer Quantiles (Raw)"), nrow = 1)


```














## Precipitation-mortality relationships in Tsuga

::: {.columns}
:::: {.column}
* We return to the mortality of trees in North American forests
* The dataset contains information for multiple species and years
    - there is replication within units
* For now, we focus on *Tsuga canadensis*

::::
:::: {.column}
```{r tsuga_load}
trees = fread("../vu_advstats_students/data/treedata.csv")
tsuga = trees[grep("Tsuga", species_name)]
# remove NAs
tsuga = tsuga[complete.cases(tsuga), ]
head(tsuga)
```

```{r tree_samp_size, echo=FALSE}
tab = table(trees[, .(species_name, year)])
tab = reshape2::melt(tab)
ggplot(tab, aes(x = species_name, y = as.factor(year), fill=value)) + 
	geom_tile() + scale_fill_viridis_c(option="magma") + theme_minimal() + xlab("Species") +
	ylab("Year") + labs(fill="sample size") + 
	theme(text = element_text(size=10), axis.text.x = element_text(angle=90, hjust=1)) 
```

::::
:::



## Precipitation-mortality relationships in Tsuga: H1

::: {.columns}
:::: {.column}
* **Question:** Does mortality of *Tsuga canadensis* vary with precipitation?
	- The species generally prefers moist conditions
* **Hypothesis 1**: The precipitation-mortality relationship is the same across all years (**Complete pooling**, 2 params)

::::
:::: {.column}
```{r tsuga_pool_graph, echo = FALSE, fig.width=8, warning = FALSE}
gr = graph_from_literal(died+-p, died+-N, p+-eta, p+-eta, eta+-a, eta+-b, eta+-precip, 
						a+-mu_a, a+-sig_a, b+-mu_b, b+-sig_b)
V(gr)$type = c("stochastic", rep("deterministic", 3), rep("stochastic", 2), rep("deterministic", 5))
V(gr)$source = c("known", "unknown", "known", rep("unknown", 3), rep("known", 5))
layout = rbind(died = c(0,1),  p = c(0, 0.7),  N = c(-0.5, 0.9),  eta = c(0, 0.5), a = c(-0.5, 0.4),
			   b = c(0.5, 0.4),  precip = c(0.5, 0.9), mua = c(-0.75, 0), siga = c(-0.25, 0), 
			   mub = c(0.25, 0), sigb = c(0.75, 0))
nt = ggnetwork(gr, layout=layout)
nlabs = c(expression(mu[a]), "a", "N", expression(sigma[a]), expression(eta), "p", 
		  expression(mu[b]), "b", "precip", expression(sigma[b]), "died")

grpl_pool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
	geom_nodelabel(label = nlabs, fontface = "bold", nudge_x=-0.1) +
   # geom_nodelabel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05) + 
   annotate(geom="label", x = 1.4, y = 0, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.4, y = 0.5, label = "Parameter layer") + 
   annotate(geom="label", x = 1.4, y = 0.95, label = "Observation layer") + 
   xlim(-0.5, 1.6) + ggtitle("Complete Pooling")
grpl_pool
```

::::
:::




## Precipitation-mortality relationships in Tsuga: H2

::: {.columns}
:::: {.column}
* **Question:** Does mortality of *Tsuga canadensis* vary with precipitation?
	- The species generally prefers moist conditions
* **Hypothesis 1**: The precipitation-mortality relationship is the same across all years (**Complete pooling**, 2 params)
* **Hypothesis 2**: The *average survival* varies by year, but the slope between precipitation and mortality is constant (**Unpooled intercepts, pooled slopes**, 17 params)
    - Sample size by year ranges from 1 to 208
::::
:::: {.column}
```{r tsuga_spool_graph, echo = FALSE, fig.width=8, warning = FALSE}
gr = graph_from_literal(died+-p, died+-N, p+-eta, precip-+eta,
						eta+-a89, eta+-a97, eta+-a94, eta+-a02, eta+-a01, eta+-a09,
						eta+-a07, eta+-a06, eta+-a98, eta+-a10, eta+-a08, eta+-a12,
						eta+-a11, eta+-a05, eta+-a04, eta+-a03,
						eta+-b, b+-mub, b+-sigb, 
						mua-+a89, mua-+a97, mua-+a94, mua-+a02, mua-+a01, mua-+a09,
						mua-+a07, mua-+a06, mua-+a98, mua-+a10, mua-+a08, mua-+a12,
						mua-+a11, mua-+a05, mua-+a04, mua-+a03,
						siga-+a89, siga-+a97, siga-+a94, siga-+a02, siga-+a01, siga-+a09,
						siga-+a07, siga-+a06, siga-+a98, siga-+a10, siga-+a08, siga-+a12,
						siga-+a11, siga-+a05, siga-+a04, siga-+a03)
V(gr)$type = c("stochastic", rep("deterministic", 4), rep("stochastic", 17), rep("deterministic", 4)) 
V(gr)$source = c("known", "unknown", "known", "unknown", "known", rep("unknown", 17), rep("known", 4))
layout = rbind(died = c(0, 1), p = c(0,0.7), N = c(-0.5, 0.9),  eta = c(0, 0.5), precip = c(0.5, 0.9),
	  cbind(seq(-0.8, -0.2, length.out = 16), rep(0.4, 16)), b = c(0.5, 0.4), 
	  mub = c(0.25, 0), sigb = c(0.75, 0), mua = c(-0.75, 0), siga = c(-0.25, 0))
nt = ggnetwork(gr, layout=layout)
nlabs = c(rep(NA, 9), "N", rep(NA, 10), "p", NA, "b", "precip", NA, "died")


grpl_slpool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=4) + 
	geom_nodelabel(label = nlabs, nudge_x=-0.1) +
   annotate(geom="label", x = -0.1, y = 0.45, label = expression(a[1989-2012])) + 
   annotate(geom="label", x = 0.5, y = 0.55, label = expression(eta)) + 
   annotate(geom="label", x = -0.05, y = 0.05, label = expression(mu[a])) + 
   annotate(geom="label", x = 0.4, y = 0.05, label = expression(sigma[a])) + 
   annotate(geom="label", x = 0.65, y = 0.05, label = expression(mu[b])) + 
   annotate(geom="label", x = 0.95, y = 0.05, label = expression(sigma[b])) + 
   annotate(geom="label", x = 1.5, y = 0, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.5, y = 0.5, label = "Parameter layer") + 
   annotate(geom="label", x = 1.5, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.7) + ggtitle("Unooled Intercepts")
grpl_slpool
```
::::
:::



## Precipitation-mortality relationships in Tsuga: H3

::: {.columns}
:::: {.column}
* **Question:** Does mortality of *Tsuga canadensis* vary with precipitation?
	- The species generally prefers moist conditions
* **Hypothesis 1**: The precipitation-mortality relationship is the same across all years (**Complete pooling**, 2 params)
* **Hypothesis 2**: The *average survival* varies by year, but the slope between precipitation and mortality is constant (**Unpooled intercepts, pooled slopes**, 17 params)
    - Sample size by year ranges from 1 to 208
* **Hypothesis 3**: There is a different regression line for each year (**No pooling**, 32 parameters)

::::
:::: {.column}
```{r tsuga_unpool_graph, echo = FALSE, fig.width=8, warning = FALSE}
gr = graph_from_literal(died+-p, died+-N, p+-eta, precip-+eta,
						eta+-a89, eta+-a97, eta+-a94, eta+-a02, eta+-a01, eta+-a09,
						eta+-a07, eta+-a06, eta+-a98, eta+-a10, eta+-a08, eta+-a12,
						eta+-a11, eta+-a05, eta+-a04, eta+-a03,
						eta+-b89, eta+-b97, eta+-b94, eta+-b02, eta+-b01, eta+-b09,
						eta+-b07, eta+-b06, eta+-b98, eta+-b10, eta+-b08, eta+-b12,
						eta+-b11, eta+-b05, eta+-b04, eta+-b03,
						mua-+a89, mua-+a97, mua-+a94, mua-+a02, mua-+a01, mua-+a09,
						mua-+a07, mua-+a06, mua-+a98, mua-+a10, mua-+a08, mua-+a12,
						mua-+a11, mua-+a05, mua-+a04, mua-+a03,
						siga-+a89, siga-+a97, siga-+a94, siga-+a02, siga-+a01, siga-+a09,
						siga-+a07, siga-+a06, siga-+a98, siga-+a10, siga-+a08, siga-+a12,
						siga-+a11, siga-+a05, siga-+a04, siga-+a03,
						mub-+b89, mub-+b97, mub-+b94, mub-+b02, mub-+b01, mub-+b09,
						mub-+b07, mub-+b06, mub-+b98, mub-+b10, mub-+b08, mub-+b12,
						mub-+b11, mub-+b05, mub-+b04, mub-+b03,
						sigb-+b89, sigb-+b97, sigb-+b94, sigb-+b02, sigb-+b01, sigb-+b09,
						sigb-+b07, sigb-+b06, sigb-+b98, sigb-+b10, sigb-+b08, sigb-+b12,
						sigb-+b11, sigb-+b05, sigb-+b04, sigb-+b03)
V(gr)$type = c("stochastic", rep("deterministic", 4), rep("stochastic", 32), rep("deterministic", 4)) 
V(gr)$source = c("known", "unknown", "known", "unknown", "known", rep("unknown", 32), rep("known", 4))
layout = rbind(died = c(0, 1), p = c(0,0.7), N = c(-0.5, 0.9),  eta = c(0, 0.5), precip = c(0.5, 0.9),
	  cbind(seq(0.2, 0.8, length.out = 16), rep(0.4, 16)),
	  cbind(seq(-0.8, -0.2, length.out = 16), rep(0.4, 16)),
	  mub = c(0.25, 0), sigb = c(0.75, 0), mua = c(-0.75, 0), siga = c(-0.25, 0))
nt = ggnetwork(gr, layout=layout)
nlabs = c(rep(NA, 9), "N", rep(NA, 10), "p", rep(NA, 9), "precip", rep(NA, 9), "died")
# rep(NA, 20)

grpl_nopool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=4) + 
	geom_nodelabel(label = nlabs, nudge_x=-0.1) +
   annotate(geom="label", x = -0.1, y = 0.45, label = expression(a[1989-2012])) + 
   annotate(geom="label", x = 1, y = 0.45, label = expression(b[1989-2012])) + 
   annotate(geom="label", x = 0.5, y = 0.55, label = expression(eta)) + 
   annotate(geom="label", x = -0.05, y = 0.05, label = expression(mu[a])) + 
   annotate(geom="label", x = 0.4, y = 0.05, label = expression(sigma[a])) + 
   annotate(geom="label", x = 0.65, y = 0.05, label = expression(mu[b])) + 
   annotate(geom="label", x = 0.95, y = 0.05, label = expression(sigma[b])) + 
   annotate(geom="label", x = 1.5, y = 0, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.5, y = 0.5, label = "Parameter layer") + 
   annotate(geom="label", x = 1.5, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.7) + ggtitle("No Pooling")
grpl_nopool
```

::::
:::

## Pooled model: code

```{stan stan_tsuga_pool, output.var="tsuga_pooled", cache = TRUE}
data {
	// number of data points
	int <lower=0> n; 
	
	// number of trees in each plot
	int <lower=1> n_trees [n]; 

	// number died
	int <lower=0> died [n]; 
	vector [n] precip;
}
parameters {
	real a;
	real b;
}
transformed parameters {
	vector <lower=0, upper=1> [n] p;
	p = inv_logit(a + b * precip);
}
model {
	died ~ binomial(n_trees, p);
	a ~ normal(0, 10);
	b ~ normal(0, 5);
}
generated quantities {
	// we use generated quantities to keep track of log likelihood and
	// deviance, useful for model selection
	// and also to perform poserior predictive simulations
	real deviance = 0;
	vector [n] loglik;
	int ppd_died [n];
	for (i in 1:n) {
		loglik[i] = binomial_lpmf(died[i] | n_trees[i], p[i]);
		deviance += loglik[i];
		ppd_died[i] = binomial_rng(20, p[i]);
	}
	deviance = -2 * deviance;
}
```



## Pooled models trade accuracy for precision

* All data for a single set of estimates
	- highly precise parameter estimates

```{r tsuga_pool_fit, cache = TRUE, echo = FALSE}
## Fit the model
## note that I have rescaled precipitaiton
## additionally, we add the year variable as a factor
precip = scale(tsuga$tot_annual_pp) 
standat = with(tsuga, list(
	n = length(died),
	n_trees = n,
	died = died,
	precip = precip[,1],
	year = as.factor(year)))  
fit_pooled = sampling(tsuga_pooled, chains=4, iter=3000, refresh=0, data = standat)
```

```{r plotfuns, echo = FALSE}
prob_ci = function(pr, data) {
	quants = apply(pr, 2, quantile, c(0.5, 0.05, 0.95))
	data.table(pr_obs = data$died/data$n_trees, pred = quants[1,], 
						lower = quants[2,], upper = quants[3,],
						year = as.factor(tsuga$year))
}
obs_pred_plot = function(probci) {
	ggplot(probci, aes(x=pr_obs, y = pred, colour=year)) + geom_point() + 
		geom_abline(intercept=0, slope=1, lty=2) + 
		geom_errorbar(aes(x=pr_obs, ymin=lower, ymax=upper, width=0)) + 
		theme_minimal() + xlim(0,1) + ylim(0,1) + 
		xlab("Observed proportion surviving") + ylab("Predicted proportion surviving")
}
# compute errors
# squared error per data point
rmse_tsuga = function(probs, data) {
	se_sample = sweep(probs, 2, data$died/data$n_trees, `-`)^2
	rmse_year = apply(se_sample, 1, \(x) tapply(x, data$year, \(y) sqrt(mean(y))))
	rmse_year = t(apply(rmse_year, 1, quantile, c(0.5, 0.05, 0.95)))
	rmse_year_dt = data.table(rmse_year)
	colnames(rmse_year_dt) = c("rmse", "lower", "upper")
	rmse_year_dt$year = rownames(rmse_year)
	rmse_year_dt$n = as.vector(table(data$year))
	rmse_year_dt
}
err_plot = function(errdt) {
	ggplot(errdt, aes(x = year, y = rmse, colour=n)) + geom_point() + 
		geom_errorbar(aes(x = year, ymin=lower, ymax=upper, width=0)) + 
		theme_minimal() + scale_colour_viridis_c(option="magma") + ylab("Mean Prediction Error")
}
rc_plot = function(samp) {
	xx = seq(min(precip), max(precip), length.out=200)
	pred = apply(samp, 1, \(par) plogis(par[1] + par[2] * xx))
	quants = t(apply(pred, 1, quantile, c(0.5, 0.05, 0.95)))
	colnames(quants) = c("pr", "lower", "upper")
	pldat = data.table(quants)
	pldat$x = xx * attr(precip, "scaled:scale") + attr(precip, "scaled:center")
	ggplot(pldat, aes(x = x, y = pr)) +geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.5) + 
		geom_line(col='blue') + ylim(0, 1) + theme_minimal() + 
		xlab("Precipitation") + ylab("pr(death)")
}
```

```{r plot_tsuga_pooledfit, cache = TRUE, echo = FALSE, fig.width=15}
probs = as.matrix(fit_pooled, pars='p')
par_samples = as.matrix(fit_pooled, pars=c("a", "b"))
ci_pooled = prob_ci(probs, standat)
errs = rmse_tsuga(probs, standat)
pl_probs_pooled = obs_pred_plot(ci_pooled)
pl_err_pooled = err_plot(errs)
pl_intervals_pooled = mcmc_intervals(par_samples) + theme_minimal()
rc = rc_plot(par_samples)

grid.arrange(pl_intervals_pooled, rc, ncol=2)
```


## Pooled models trade accuracy for precision

* All data for a single set of estimates
	- highly precise parameter estimates
* High prediction errors for individual groups 
* Groups with small samples biased towards the mean

```{r plot_tsuga_pooledfit2, cache = TRUE, echo = FALSE, fig.width=15}
grid.arrange(pl_probs_pooled, pl_err_pooled, ncol=2)
```


## Unpooled model: code

```{stan tsuga_unpooled_code, output.var="tsuga_unpooled_dead", eval = FALSE}
data {
	// not the complete program, only differences from pooled model

	// grouping variables
	// year_id is an integer starting at 1 (the earliest year)
	// ending at n_groups (the latest year)
	// we use this value as an index for any group-level effects
	int <lower=1> n_groups;
	int <lower=1, upper = n_groups> year_id [n];
}
parameters {
	// one intercept per group
	vector [n_groups] a;
}
transformed parameters {
	// a is different for each data point, depending on the group
	// so we need a loop to compute this
	for(i in 1:n) {
		int gid = year_id[i];
		p[i] = inv_logit(a[gid] + b * precip[i]);
	}
}

```

```{r tsuga_unpooled_compile, cache = TRUE, message = FALSE, error = FALSE, echo = FALSE}
# compile the model (below)
tsuga_unpooled = stan_model("../vu_advstats_students/stan/tsuga_unpooled.stan")
```


## Unpooled model: code


```{r}
# factor variables must be converted to integers for stan
standat$year_id = as.integer(standat$year)

# we also need to tell stan how many groups (i.e., years) there are
standat$n_groups = max(standat$year_id)
```



```{r fit_tsuga_unpooled, cache = TRUE}
fit_unpooled = sampling(tsuga_unpooled, chains=4, iter=3000, refresh=0, 
						data = standat)
```



## Unpooled models use less data per parameter

```{r plot_unpooled, cache = TRUE, echo = FALSE, fig.width=15}

rc_plot_year = function(samp) {
	yearnames = sort(as.integer(as.character(levels(standat$year))))
	yearids = c(1, 7, 8, 16)
	xx = seq(min(precip), max(precip), length.out=200)
	pldat = lapply(yearids, \(yid) {
		pred = apply(samp, 1, \(par) plogis(par[yid] + par[max(yearids)+1] * xx))
		quants = t(apply(pred, 1, quantile, c(0.5, 0.05, 0.95)))
		colnames(quants) = c("pr", "lower", "upper")
		pldat = data.table(quants)
		pldat$x = xx * attr(precip, "scaled:scale") + attr(precip, "scaled:center")
		pldat$year = yearnames[yid]
		pldat
	})
	pldat = rbindlist(pldat)
	pldat$year = as.factor(pldat$year)
	
	ggplot(pldat, aes(x = x, y = pr, colour = year)) + 
		geom_ribbon(aes(ymin = lower, ymax = upper, fill = year), alpha = 0.3) + 
		geom_line() + ylim(0, 1) + theme_minimal() + 
		xlab("Precipitation") + ylab("pr(death)")
}

probs = as.matrix(fit_unpooled, pars='p')
par_samples = as.matrix(fit_unpooled, pars=c("a", "b"))
ci_unpooled = prob_ci(probs, standat)
errs = rmse_tsuga(probs, standat)
pl_probs_unpooled = obs_pred_plot(ci_unpooled)
pl_err_unpooled = err_plot(errs)
pl_intervals_unpooled = mcmc_intervals(par_samples) + theme_minimal()
rc = rc_plot_year(par_samples)

grid.arrange(pl_intervals_unpooled, rc, ncol=2)
```



## Unpooled models use less data per parameter

* Very imprecise, especially for groups with few samples
* Prediction to new groups (years) impossible

```{r plot_unpooled 2, cache = TRUE, echo = FALSE, fig.width=15}
grid.arrange(pl_probs_unpooled, pl_err_unpooled, ncol=2)
```




## Compromise: partial pooling
::: {.columns}
:::: {.column}

* We don't really expect each year to be independent
    - it's all one species, response to temperature should be similar
    - some years are better or worse than others
* Imagine instead there is a population of possible years, each with its own mortality
* This population has a true mean and a true variance
* The samples we've taken will come from that distribution
* This can tell us something about all possible years, not just these years


::::
:::: {.column}


```{r graph_tsuga_parpool, echo = FALSE, fig.width=8, warning = FALSE}
gr = graph_from_literal(died+-p, died+-N, p+-eta, precip-+eta,
						eta+-a89, eta+-a97, eta+-a94, eta+-a02, eta+-a01, eta+-a09,
						eta+-a07, eta+-a06, eta+-a98, eta+-a10, eta+-a08, eta+-a12,
						eta+-a11, eta+-a05, eta+-a04, eta+-a03,
						eta+-b89, eta+-b97, eta+-b94, eta+-b02, eta+-b01, eta+-b09,
						eta+-b07, eta+-b06, eta+-b98, eta+-b10, eta+-b08, eta+-b12,
						eta+-b11, eta+-b05, eta+-b04, eta+-b03,
						mua-+a89, mua-+a97, mua-+a94, mua-+a02, mua-+a01, mua-+a09,
						mua-+a07, mua-+a06, mua-+a98, mua-+a10, mua-+a08, mua-+a12,
						mua-+a11, mua-+a05, mua-+a04, mua-+a03,
						siga-+a89, siga-+a97, siga-+a94, siga-+a02, siga-+a01, siga-+a09,
						siga-+a07, siga-+a06, siga-+a98, siga-+a10, siga-+a08, siga-+a12,
						siga-+a11, siga-+a05, siga-+a04, siga-+a03,
						mub-+b89, mub-+b97, mub-+b94, mub-+b02, mub-+b01, mub-+b09,
						mub-+b07, mub-+b06, mub-+b98, mub-+b10, mub-+b08, mub-+b12,
						mub-+b11, mub-+b05, mub-+b04, mub-+b03,
						sigb-+b89, sigb-+b97, sigb-+b94, sigb-+b02, sigb-+b01, sigb-+b09,
						sigb-+b07, sigb-+b06, sigb-+b98, sigb-+b10, sigb-+b08, sigb-+b12,
						sigb-+b11, sigb-+b05, sigb-+b04, sigb-+b03,
						mu_mu_a-+mua, sig_mu_a-+mua, alpha_sig_a-+siga, beta_sig_a-+siga,
						mu_mu_b-+mub, sig_mu_b-+mub, alpha_sig_b-+sigb, beta_sig_b-+sigb)
V(gr)$type = c("stochastic", rep("deterministic", 4), rep("stochastic", 32), rep("stochastic", 4), rep("deterministic", 8)) 
V(gr)$source = c("known", "unknown", "known", "unknown", "known", rep("unknown", 36), rep("known", 8))
layout = rbind(died = c(0, 1), p = c(0,0.8), N = c(-0.5, 0.95),  eta = c(0, 0.7), precip = c(0.5, 0.95),
	  cbind(seq(0.2, 0.8, length.out = 16), rep(0.5, 16)),
	  cbind(seq(-0.8, -0.2, length.out = 16), rep(0.5, 16)),
	  mub = c(0.25, 0.25), sigb = c(0.75, 0.25), mua = c(-0.75, 0.25), siga = c(-0.25, 0.25),
	  mu_mu_b = c(0.15, 0), sig_mu_b = c(0.35, 0), alpha_sig_b = c(0.65, 0), beta_sig_b = c(0.85, 0),
	  mu_mu_a = c(-0.85, 0), sig_mu_a = c(-0.65, 0), alpha_sig_a = c(-0.35, 0), beta_sig_a = c(-0.15, 0))

nt = ggnetwork(gr, layout=layout)
nlabs = c(rep(NA, 11), "N", rep(NA, 12), "p", rep(NA, 11), "precip", rep(NA, 11), "died")

grpl_parpool = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=4) + 
	geom_nodelabel(label = nlabs, nudge_x=-0.1) +
   annotate(geom="label", x = -0.1, y = 0.45, label = expression(a[1989-2012])) + 
   annotate(geom="label", x = 1, y = 0.45, label = expression(b[1989-2012])) + 
   annotate(geom="label", x = 0.55, y = 0.7, label = expression(eta)) + 
   annotate(geom="label", x = -0.05, y = 0.3, label = expression(mu[a])) + 
   annotate(geom="label", x = -0.05, y = 0.05, label = expression(mu[mu[a]])) + 
   annotate(geom="label", x = 0.15, y = 0.05, label = expression(sigma[mu[a]])) + 
   annotate(geom="label", x = 0.35, y = 0.3, label = expression(sigma[a])) + 
   annotate(geom="label", x = 0.25, y = -0.05, label = expression(mu[sigma[a]])) + 
   annotate(geom="label", x = 0.4, y = -0.05, label = expression(sigma[sigma[a]])) + 
   annotate(geom="label", x = 0.65, y = 0.3, label = expression(mu[b])) + 
   annotate(geom="label", x = 0.55, y = 0.05, label = expression(mu[mu[b]])) + 
   annotate(geom="label", x = 0.7, y = 0.05, label = expression(sigma[mu[b]])) + 
   annotate(geom="label", x = 0.95, y = 0.3, label = expression(sigma[b])) + 
   annotate(geom="label", x = 0.85, y = -0.05, label = expression(mu[sigma[b]])) + 
   annotate(geom="label", x = 1, y = -0.05, label = expression(sigma[sigma[b]])) + 
   annotate(geom="label", x = 1.5, y = 0, label = "Hyperprior layer") + 
   annotate(geom="label", x = 1.5, y = 0.25, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.5, y = 0.5, label = "Parameter layer") + 
   annotate(geom="label", x = 1.5, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.7) + ggtitle("Partial Pooling")
grpl_parpool

```


::::
:::


## Partial Pooling: Code



```{stan tsuga_parpooled_code, output.var="tsuga_parpooled_dead", eval = FALSE}
data {
	// not the complete program, only differences from pooled model

	// grouping variables
	// year_id is an integer starting at 1 (the earliest year)
	// ending at n_groups (the latest year)
	// we use this value as an index for any group-level effects
	int <lower=1> n_groups;
	int <lower=1, upper = n_groups> year_id [n];
}
parameters {
	// one intercept and one slope per group
	vector [n_groups] a;
	vector [n_groups] b;

	// hyperparameters describe higher-level structure in the data
	// in this case both the a's and b's come from populations
	// with their own mean and variance to be estimated from the data
	real a_mu;
	real <lower=0> a_sig;
	real b_mu;
	real <lower=0> b_sig;
}
transformed parameters {
	for(i in 1:n) {
		int gid = year_id[i];
		p[i] = inv_logit(a[gid] + b[gid] * precip[i]);
	}
}
model {
	// The priors are now estimated from the data
	a ~ normal(a_mu, a_sig);
	b ~ normal(b_mu, b_sig);
	
	// hyperpriors describe what we know about higher (group-level) structure
	a_mu ~ normal(0, 20);
	b_mu ~ normal(0, 20);
	// half cauchy is common for hierarchical stdev
	a_sig ~ cauchy(0, 20);
	b_sig ~ cauchy(0, 20);

}
```

```{r tsuga_parpooled_compile, cache = TRUE, message = FALSE, error = FALSE, echo = FALSE, warning = FALSE, results = 'hide'}
# compile the model (below)
tsuga_ppool = stan_model("../vu_advstats_students/stan/tsuga_parpool.stan")
fit_ppool = sampling(tsuga_ppool, chains=4, iter=3000, refresh=0, 
						data = standat)
```



## Partial pooling is a compromise

* for a given group, we combine the information for this group with information from all groups
* balances precision and accuracy
* can be best approach for new groups
* weak/undersampled groups can "borrow strength" from others

```{r, cache = TRUE, echo = FALSE, fig.width=15}
rc_plot_year_slope = function(samp) {
	yearnames = sort(as.integer(as.character(levels(standat$year))))
	yearids = c(1, 7, 8, 16)
	xx = seq(min(precip), max(precip), length.out=200)
	pldat = lapply(yearids, \(yid) {
		pred = apply(samp, 1, \(par) plogis(par[yid] + par[max(yearids)+yid] * xx))
		quants = t(apply(pred, 1, quantile, c(0.5, 0.05, 0.95)))
		colnames(quants) = c("pr", "lower", "upper")
		pldat = data.table(quants)
		pldat$x = xx * attr(precip, "scaled:scale") + attr(precip, "scaled:center")
		pldat$year = yearnames[yid]
		pldat
	})
	pldat = rbindlist(pldat)
	pldat$year = as.factor(pldat$year)
	
	ggplot(pldat, aes(x = x, y = pr, colour = year)) + 
		geom_ribbon(aes(ymin = lower, ymax = upper, fill = year), alpha = 0.3) + 
		geom_line() + ylim(0, 1) + theme_minimal() + 
		xlab("Precipitation") + ylab("pr(death)")
}

probs = as.matrix(fit_ppool, pars='p')
par_samples = as.matrix(fit_ppool, pars=c("a", "b"))
ci_ppool = prob_ci(probs, standat)
errs = rmse_tsuga(probs, standat)
pl_probs_ppool = obs_pred_plot(ci_ppool)
pl_err_ppool = err_plot(errs)
pl_intervals_ppool = mcmc_intervals(par_samples) + theme_minimal()
rc = rc_plot_year_slope(par_samples)

grid.arrange(pl_intervals_ppool, rc, ncol=2)
```


## Partial pooling is a compromise
```{r, cache = TRUE, echo = FALSE, fig.width=15}
grid.arrange(pl_probs_ppool, pl_err_ppool, ncol=2)
```





## Pooling comparison
```{r echo = FALSE, fig.width=18}
grid.arrange(pl_err_pooled + ggtitle("Pooled") + ylim(0, 0.9), 
			 pl_err_unpooled + ggtitle("Unpooled") + ylim(0, 0.9), 
			 pl_err_ppool + ggtitle("Partially Pooled") + ylim(0, 0.9), ncol=3)
```

## Pooling comparison
```{r echo = FALSE, fig.width=18}
grid.arrange(pl_intervals_pooled + ggtitle("Pooled"), 
			 pl_intervals_unpooled + ggtitle("Unpooled"), 
			 pl_intervals_ppool + ggtitle("Partially Pooled"), ncol=3)
```


## When do we need hierarchical models?
* Repeated sampling within units (e.g., samples nested within plots/individuals)
* Inference at multiple levels of organisation
    - Covariates at multiple spatial scales
* Uneven sampling among units
* Accounting for nonindependence of samples
* Avoiding pre-averaging
    - Don't: perform repeat samples on a unit, perform analysis on the average
    - Do: Build an HM accounting for variability within and among units
* A common category of HM is often called mixed modeling
    - All mixed models are hierarchical, not all hierarchical models are mixed models



## Designing hierarchical models in Stan
::: {.columns}
:::: {.column}
* You must specify data/objects at all levels
* Often we use an indexing variable to link observations to their group
* This variable **must** start at 1 and end at *n_groups*

::::
:::: {.column}
```{stan output.var="stan_hm", eval = FALSE}
data {
	// group-level objects
	int <lower=1> n_groups;
	int <lower=1, upper=n_groups> group_id [n];
}
parameters {
	vector [n_groups] a; 
	
	// hyperparameters
	real a_mu;
	real a_sig;
}
transformed parameters {
	pr[i] = inv_logit(a[group_id[i]]);
}
model {
	a ~ normal(a_mu, a_sig);  // hierarchical prior for a
}
```
::::
:::


## Designing hierarchical models in Stan
::: {.columns}
:::: {.column}
* You must specify data/objects at all levels
* Often we use an indexing variable to link observations to their group
* This variable **must** start at 1 and end at *n_groups*
* Multiple non-nested groups are possible



```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, p+-precip,
						p+-a1_n, p+-a2_n, p+-b,
						a1_n+-"μ_a1", a1_n+-"σ_a1", 
						a2_n+-"μ_a2", a2_n+-"σ_a2",
						b+-"μ_b=0", b+-"σ_b=5", 
						"μ_a1"+-"N(0,10)", "σ_a1"+-"G(0.1,0.1)",
						"μ_a2"+-"N(0,10)", "σ_a2"+-"G(0.1,0.1)")
V(gr)$type = c("random", rep("deterministic", 3), rep("random", 7), rep("deterministic", 4))
V(gr)$source = c("known", "unknown", rep("known", 2), rep("unknown", 7), rep("known", 4))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  0.5,1.8,
				  -0.5,1,  -1,1,  0.5,1,  
				   -0.7,0, -0.3,0,  -1.2,0, -0.8,0,  0.25,0,  0.75,0,  -0.8,-1, -0.3,-1), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_hm1 = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = 0, label = "Hyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.3, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.67, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5)
grpl_hm1
```





::::
:::: {.column}
```{stan output.var="stan_hm", eval = FALSE}
data {
	int n; // number of data points
	int died [n]
	int N[n];
	vector [n] precip;

	// group-level objects
	int <lower=1> n_group1;
	int <lower=1, upper=n_group1> group1_id [n];

	int <lower=1> n_group2;
	int <lower=1, upper=n_group2> group2_id [n];
}
parameters {
	vector [n_group1] a1; 
	vector [n_group2] a2; 
	
	// hyperparameters
	real a1_mu;
	real <lower=0> a1_sig;
	real a2_mu;
	real <lower=0> a2_sig;
}
transformed parameters {
	vector [n] pr;
	for(i in 1:n)
		pr[i] = inv_logit(a1[group1_id[i]] + a2[group2_id[i]] + b*precip[i]);
}
model {
	died ~ binomial(N, pr); // likelihood

	a1 ~ normal(a1_mu, a1_sig);  // hierarchical prior for a1
	a2 ~ normal(a2_mu, a2_sig);  // hierarchical prior for a2

	// hyperpriors
	a1_mu ~ normal(0,10)
	a2_mu ~ normal(0,10)
	a1_sig ~ gamma(0.1, 0.1);
	a2_sig ~ gamma(0.1, 0.1);
}
```

::::
:::





## Designing hierarchical models in Stan
::: {.columns}
:::: {.column}
* Nested groups add an additional hierarchical layer


```{r, echo = FALSE, fig.width=8}
gr = graph_from_literal(died+-p, died+-N, p+-precip,
						p+-a1_n, a1_n+-a2_n, p+-b,
						a1_n+-"σ_a1", 
						a2_n+-"μ_a2", a2_n+-"σ_a2",
						b+-"μ_b=0", b+-"σ_b=5", 
						"σ_a1"+-"G(0.1,0.1)",
						"μ_a2"+-"N(0,10)", "σ_a2"+-"G(0.1,0.1)")
V(gr)$type = c("random", rep("deterministic", 3), rep("random", 6), rep("deterministic", 4))
V(gr)$source = c("known", "unknown", rep("known", 2), rep("unknown", 6), rep("known", 4))
layout = matrix(c(0,2,  0,1.2,  -0.5,1.8,  0.5,1.8,
				  -0.5,1,  -0.75,0,  0.5,1,  
				   -0.3,0,  -1,-1, -0.5,-1, 0.25,0,  0.75,0,  -0.1,-1.2, -1,-2), byrow=TRUE, ncol=2)
nt = ggnetwork(gr, layout=layout)
grpl_hm2 = ggplot(nt, aes(x = x, y = y, xend = xend, yend = yend)) + 
   geom_edges(colour="gray50", arrow=arrow(length = unit(6, "pt"), type = "closed")) + 
   theme_blank() + geom_nodes(aes(color=type, shape = source), size=6) + 
   geom_nodelabel_repel(aes(label = name), fontface = "bold", nudge_x=-0.1, nudge_y=0.05, segment.colour = "#99999955") + 
   annotate(geom="label", x = 1.3, y = 0, label = "Hyperhyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.25, label = "Hyperprior layer") + 
   annotate(geom="label", x = 1.3, y = 0.5, label = "Hyperparameter layer") + 
   annotate(geom="label", x = 1.3, y = 0.75, label = "Parameter layer") + 
   annotate(geom="label", x = 1.3, y = 1, label = "Observation layer") + 
   xlim(-0.5, 1.5)
grpl_hm2
```


::::
:::: {.column}
```{stan output.var="stan_hm", eval = FALSE}
data {
	int n; // number of data points
	int died [n]
	int N[n];
	vector [n] temperature;

	// group-level objects
	int <lower=1> n_group1;
	int <lower=1, upper=n_group1> group1_id [n];

	int <lower=1> n_group2;
	int <lower=1, upper=n_group2> group2_id [n_group1];
}
parameters {
	vector [n_group1] a1; 
	vector [n_group2] a2; 
	
	// hyperparameters
	real <lower=0> a1_sig;
	real a2_mu;
	real <lower=0> a2_sig;
}
transformed parameters {
	vector [n] pr;
	for(i in 1:n)
		pr[i] = inv_logit(a1[group1_id[i]] + b*precip[i]);
}
model {
	died ~ binomial(N, pr); // likelihood

	for(i in n_group1)
		a1 ~ normal(a2[i], a1_sig);  // hierarchical prior for a1
	// hyperpriors
	a2 ~ normal(a2_mu, a2_sig);  // hierarchical prior for a2
	a1_sig ~ gamma(0.1, 0.1);
	
	// hyperhyperprior
	a2_mu ~ normal(0,10)
}
```
::::
:::




## Posterior predictive distributions
::: {.columns}
:::: {.column}
* Do we want to predict new observations from a known group? 
	- e.g: What is the PPD for trees in 1989?
    - Use **generated quantities** block in Stan
* Or new observations from an unknown group?
    - Simulate new values for each param, drawn from hyper params
    - Then simulate the individual observations

::::
:::: {.column}

```{r}
sim1 = function(amu, asig, bmu, bsig, N, precip) {
	a = rnorm(length(precip), amu, asig)
	b = rnorm(length(precip), bmu, bsig)
	p = plogis(a + b*precip)
	rbinom(length(precip), N, p)
}
```
::::
:::



## Posterior predictive distributions
::: {.columns}
:::: {.column}
```{r cache=TRUE}
newx = seq(min(standat$precip), max(standat$precip), length.out=400)
pars = data.frame(as.matrix(fit_ppool, pars=c("a_mu", "a_sig", "b_mu", "b_sig")))

# For our hypothetical, we need to decide how many trees we would see
# more trees means less sampling uncertainty
N = 20
sims = mapply(sim1, amu = pars$a_mu, asig = pars$a_sig,
			  bmu = pars$b_mu, bsig = pars$b_sig, 
			  MoreArgs = list(N = 20, precip = newx))
sim_quantiles = apply(sims, 1, quantile, c(0.5, 0.05, 0.95))
```

::::
:::: {.column}


```{r echo = FALSE}
sim_qs = data.frame(t(sim_quantiles)/N)
colnames(sim_qs) = c("died", "lower", "upper")
## undo the scaling so we can see the plot on the original scale
sim_qs$precip = (newx * sd(tsuga$tot_annual_pp)) + mean(tsuga$tot_annual_pp)
ggplot(sim_qs, aes(x = precip, y = died)) + 
	geom_ribbon(aes(ymin = lower, ymax = upper), fill = cols[1], alpha = 0.4) + 
	geom_line(col = cols[1], linewidth = 0.8) + 
	theme_minimal() + xlab("Total Annual Precipitation(mm)") + 
	ylab("Predicted Proportion Dead") + ylim(0, 1)
```
::::
:::
